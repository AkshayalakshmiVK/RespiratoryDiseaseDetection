{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## InfoGAN based Respiratory Disease Detection from respiratory sounds with Deep neural network\n",
        "\n",
        "This is a deep learning based model using a deep neural network to detect respiratory diseases from the respiratory sounds. \n",
        "\n",
        "Prior to feeding the model to the deep netwok, the sounds are pre-processed for noise reduction. \n",
        "\n",
        "They are then fed to an independent component analysis module for removing heart sounds.\n",
        "\n",
        "The processed sound audio frames are now sliced to target the respiratory cycles and mfcc features are extracted. \n",
        "\n",
        "The extracted sounds are now fed into an Information-maximising GAN to augment the data with new audio samples to prevent the unbalance in the dataset.\n",
        "\n",
        "These audios are now fed to a deep neural network to detect the respiratory disease present in the audio.\n",
        "\n",
        "The proposed model performs better in prediction in both training and test sets."
      ],
      "metadata": {
        "id": "Q-Muc1MEvQmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Required Libraries"
      ],
      "metadata": {
        "id": "o2DJ199lUrSb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ7huis681mU"
      },
      "outputs": [],
      "source": [
        "from scipy import signal\n",
        "from scipy.signal import kaiserord, lfilter, firwin, freqz\n",
        "import numpy as np\n",
        "import librosa\n",
        "from pylab import figure, clf, plot, xlabel, ylabel, xlim, ylim, title, grid, axes, show\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "import os\n",
        "import librosa\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independant Component Analysis"
      ],
      "metadata": {
        "id": "Si9BS2DUUyLc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zGeqsZy81mW"
      },
      "outputs": [],
      "source": [
        "def g(x):\n",
        "    return np.tanh(x)\n",
        "def g_der(x):\n",
        "    return 1 - g(x) * g(x)\n",
        "def center(X):\n",
        "    X = np.array(X)\n",
        "    mean = X.mean(axis=0, keepdims=True)\n",
        "    \n",
        "    return X- mean\n",
        "def whitening(X):\n",
        "    cov = np.cov(X)\n",
        "    d, E = np.linalg.eigh(cov)\n",
        "    D = np.diag(d)\n",
        "    D_inv = np.sqrt(np.linalg.inv(D))\n",
        "    X_whiten = np.dot(E, np.dot(D_inv, np.dot(E.T, X)))\n",
        "    return X_whiten\n",
        "\n",
        "def calculate_new_w(w, X):\n",
        "    w_new = (X * g(np.dot(w.T, X))).mean(axis=1) - g_der(np.dot(w.T, X)).mean() * w\n",
        "    w_new /= np.sqrt((w_new ** 2).sum())\n",
        "    return w_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlQxY0xl81mX"
      },
      "outputs": [],
      "source": [
        "def ica(X, iterations, tolerance=1e-5):\n",
        "    X = center(X)\n",
        "    #X = whitening(X)\n",
        "    components_nr = X.shape[0]\n",
        "    #print(X.shape[0])\n",
        "    W = np.zeros((components_nr, components_nr), dtype=X.dtype)\n",
        "    for i in range(components_nr):\n",
        "        w = np.random.rand(components_nr)\n",
        "        for j in range(iterations):\n",
        "            w_new = calculate_new_w(w, X)\n",
        "            if i >= 1:\n",
        "                w_new -= np.dot(np.dot(w_new, W[:i].T), W[:i])\n",
        "            distance = np.abs(np.abs((w * w_new).sum()) - 1)\n",
        "            w = w_new\n",
        "            if distance < tolerance:\n",
        "                break\n",
        "        W[i, :] = w\n",
        "    S = np.dot(W, X)\n",
        "    return S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv4ynUvz81mX"
      },
      "outputs": [],
      "source": [
        "def plot_mixture_sources_predictions(X,  S):\n",
        "    fig = plt.figure()\n",
        "\n",
        "    plt.subplot(3, 1, 1)\n",
        "    for x in X:\n",
        "        plt.plot(x)\n",
        "    plt.title(\"mixtures\")\n",
        "\n",
        "    plt.subplot(3,1,3)\n",
        "    for s in S:\n",
        "        plt.plot(s)\n",
        "    plt.title(\"predicted sources\")\n",
        "    \n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQscx49G81mY"
      },
      "outputs": [],
      "source": [
        "def get_label(pid):\n",
        "  with open('C:\\\\Users\\\\Dell\\\\Desktop\\\\CIP\\\\data.txt') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      lines_ = []\n",
        "      lines_.append(list(line.split()))\n",
        "\n",
        "      if lines_[0][0] == str(pid):\n",
        "        return lines_[0][1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOSwfHAq9HW_"
      },
      "outputs": [],
      "source": [
        "def get_label(pid):\n",
        "  with open('/content/data.txt') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      lines_=[]\n",
        "      lines_.append(list(line.split()))\n",
        "      #print(lines_[0][1])\n",
        "      if lines_[0][0]==str(pid):\n",
        "         return lines_[0][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frame Slicing And Feature Extraction"
      ],
      "metadata": {
        "id": "ABzqgueolI3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mfcc(s):\n",
        "  frames = librosa.util.frame(s,11025, 11025,axis=0)\n",
        "  nm=[]\n",
        "  for frame in frames:\n",
        "    in_frames = librosa.util.frame(frame,1103, 1102,axis=0)\n",
        "    mfccs=[]\n",
        "    for in_frame in in_frames:\n",
        "      mfcc = np.mean(librosa.feature.mfcc(in_frame,n_mfcc=13,sr=22050), axis=1)\n",
        "      mfccs.append(mfcc)\n",
        "    mfccs = np.array(mfccs).reshape(130*1)\n",
        "    nm.append(mfccs)\n",
        "\n",
        "  #Principal Component Analysis\n",
        "  pca = PCA(n_components=40)\n",
        "  pca.fit(np.array(nm).reshape(40,130))\n",
        "  #print(\"Principal Components:\\n\",pca.singular_values_)\n",
        "  return np.array(pca.singular_values_).reshape(40,1)"
      ],
      "metadata": {
        "id": "tsnMqjI59-uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klZR7ZzY8_Zf",
        "outputId": "aa7a7ed7-d81b-4953-e3f4-1f82e971dd0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  \n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_NAMES=[\n",
        "            \"122_2b3_Tc_mc_LittC2SE.wav\",\n",
        "            \"226_1b1_Al_sc_Meditron.wav\",\n",
        "            \"219_2b2_Ar_mc_LittC2SE.wav\",\n",
        "            \"191_2b1_Pl_mc_LittC2SE.wav\",\n",
        "            \"191_2b1_Pr_mc_LittC2SE.wav\",\n",
        "            \"140_2b3_Ll_mc_LittC2SE.wav\",\n",
        "            \"111_1b3_Tc_sc_Meditron.wav\",\n",
        "            \"168_1b1_Al_sc_Meditron.wav\",\n",
        "            \"201_1b3_Ar_sc_Meditron.wav\",\n",
        "            \"116_1b2_Pl_sc_Meditron.wav\",\n",
        "            \"196_1b1_Pr_sc_Meditron.wav\",\n",
        "            \"169_1b2_Ll_sc_Meditron.wav\",\n",
        "            \"169_1b1_Lr_sc_Meditron.wav\",\n",
        "            \"173_1b1_Al_sc_Meditron.wav\",\n",
        "            \"206_1b1_Ar_sc_Meditron.wav\",\n",
        "            \"161_1b1_Pl_sc_Meditron.wav\",\n",
        "            \"167_1b1_Pr_sc_Meditron.wav\",\n",
        "            \"149_1b1_Lr_sc_Meditron.wav\",\n",
        "            \"105_1b1_Tc_sc_Meditron.wav\",\n",
        "            \"131_1b1_Al_sc_Meditron.wav\",\n",
        "            \"119_1b1_Ar_sc_Meditron.wav\",\n",
        "            \"165_1b1_Pl_sc_Meditron.wav\",\n",
        "            \"101_1b1_Pr_sc_Meditron.wav\",\n",
        "            \"137_1b1_Ll_sc_Meditron.wav\",\n",
        "            \"121_1p1_Tc_sc_Meditron.wav\",\n",
        "            \"123_1b1_Al_sc_Meditron.wav\",\n",
        "            \"102_1b1_Ar_sc_Meditron.wav\",\n",
        "            \"183_1b1_Pl_sc_Meditron.wav\",\n",
        "            \"159_1b1_Pr_sc_Meditron.wav\",\n",
        "            \"187_1b1_Ll_sc_Meditron.wav\",\n",
        "            \"194_1b1_Lr_sc_Meditron.wav\",\n",
        "            \"117_1b2_Tc_mc_LittC2SE.wav\",\n",
        "            \"113_1b1_Al_sc_Litt3200.wav\",\n",
        "            \"104_1b1_Ar_sc_Litt3200.wav\",\n",
        "            \"107_2b4_Pl_mc_AKGC417L.wav\",\n",
        "            \"106_2b1_Pr_mc_LittC2SE.wav\",\n",
        "            \"112_1p1_Ll_sc_Litt3200.wav\",\n",
        "            \"118_1b1_Lr_sc_Litt3200.wav\",\n",
        "            \"110_1p1_Lr_sc_Meditron.wav\"\n",
        "            ]\n",
        "TEST_DATA=[]\n",
        "TEST_LABELS=[]"
      ],
      "metadata": {
        "id": "ACGCKn6tjctJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing ICA and MFCC extraction "
      ],
      "metadata": {
        "id": "ixi9VEeWWhzx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVglPwmKtkUb"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/ICBHI_final_database'\n",
        "#endpath = 'D:\\\\Users\\\\HP\\\\Desktop\\\\CIP\\\\ICBHI_final_database\\\\Preprocessed'\n",
        "sounds = []\n",
        "labels = []\n",
        "i=1\n",
        "for file in os.listdir(path):\n",
        "  if file[-3:] == 'wav' and file[:3]!='103' and file[:3]!='108' and file[:3]!='115':\n",
        "   \n",
        "    pid = file[:3]\n",
        "    data_x, sampling_rate = librosa.load(os.path.join(path,file),res_type='kaiser_fast', duration=20)\n",
        "    \n",
        "    #adjusting audio length\n",
        "    if len(data_x)<441000:\n",
        "      diff = 441000-len(data_x)\n",
        "      da = np.full((1,diff),0)\n",
        "      data_x = np.append(data_x, da)\n",
        "\n",
        "\n",
        "    #FILTERING AND NOISE REDUCTION\n",
        "    a = signal.firwin(1081, cutoff = 100, window = \"hanning\", fs=sampling_rate,pass_zero=False)\n",
        "    filtered_x = lfilter(a, 1.0, data_x)\n",
        "    #print(np.array(filtered_x).shape)\n",
        "    \n",
        "    #ICA\n",
        "    row_new = np.zeros((1, len(filtered_x)), dtype=filtered_x.dtype)\n",
        "    new_filtered_x=np.vstack((filtered_x,row_new))\n",
        "    print(new_filtered_x.shape)\n",
        "    S = ica(new_filtered_x, iterations=10000)\n",
        "    #print(np.array(S[1]).shape)\n",
        "    #plot_mixture_sources_predictions(new_filtered_x, S)\n",
        "\n",
        "    \n",
        "    #FRAME SLICING AND FEATURE EXTRACTION\n",
        "    mfccs = np.array(get_mfcc(S[1]))\n",
        "    #print(len(mfccs))\n",
        "    sounds.append( mfccs )\n",
        "    labels.append(get_label(pid))\n",
        "\n",
        "    #BUILDING TEST SET\n",
        "    if file in TEST_NAMES:\n",
        "      TEST_DATA.append(mfccs)\n",
        "      TEST_LABELS.append(get_label(pid))\n",
        "      print(file)\n",
        "\n",
        "    #print(i)\n",
        "    i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(TEST_DATA).shape)\n",
        "print(np.array(TEST_LABELS).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J5oDFH0BOeC",
        "outputId": "0c870791-63c3-4d5f-c0c9-cd2d6df1ec4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0,)\n",
            "(0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaI-YwfYs16V",
        "outputId": "556ad1c1-beb7-4dd2-cd9f-1ec1f00bde37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "319\n",
            "40\n",
            "(40, 1)\n"
          ]
        }
      ],
      "source": [
        "print(len(sounds))\n",
        "print(len(sounds[0]))\n",
        "print(np.array(sounds[0]).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('features_sounds',np.array(sounds))\n",
        "np.save('features_labels',np.array(labels))\n",
        "np.save('TEST_sounds',np.array(TEST_DATA))\n",
        "np.save('TEST_labels',np.array(TEST_LABELS))"
      ],
      "metadata": {
        "id": "EF6RdLQRtVAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sounds = np.load(\"features_sounds.npy\")\n",
        "labels = np.load(\"features_labels.npy\")\n",
        "TEST_DATA = np.load(\"TEST_sounds.npy\")\n",
        "TEST_LABELS = np.load(\"TEST_labels.npy\")"
      ],
      "metadata": {
        "id": "_apig4BWgkF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(TEST_DATA).shape)\n",
        "print(np.array(TEST_LABELS).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Dmp5Zh0NOGG",
        "outputId": "905d1156-7035-4556-b166-7d73d78e56a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26, 40, 1)\n",
            "(26,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation - Base paper technique"
      ],
      "metadata": {
        "id": "XTtQDWr631vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(data,x):\n",
        "    noise = np.random.randn(len(data))\n",
        "    data_noise = data + x * noise\n",
        "    return data_noise\n",
        "\n",
        "def shift(data,x):\n",
        "    return np.roll(data, x)\n",
        "\n",
        "def stretch(data, rate):\n",
        "    data = librosa.effects.time_stretch(data, rate)\n",
        "    return data"
      ],
      "metadata": {
        "id": "p2Iu-0Ii4Pqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_sounds=[]\n",
        "r_labels=[]\n",
        "for i in range(len(sounds)):\n",
        "  r_sounds.append(sounds[i])\n",
        "  r_labels.append(labels[i])\n",
        "  if(labels[i]!=\"COPD\"):\n",
        "    data_noise = add_noise(data_x,0.005)\n"
      ],
      "metadata": {
        "id": "DwtZ56rL4r7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline for INFO Gan"
      ],
      "metadata": {
        "id": "q0BuP0-tYnR-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeKQNVAq81mc"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbflHFrjwUCa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow_probability as tfp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoChjI1-n9NG"
      },
      "outputs": [],
      "source": [
        "def create_gen_input(batch_size=32, noise_size=40, n_class=6, seed=None):\n",
        "  # create noise input\n",
        "  noise = tf.random.normal([batch_size, noise_size], seed=seed)\n",
        "  # Create categorical latent code\n",
        "  label = tf.random.uniform([batch_size], minval=0, maxval=6, dtype=tf.int32, seed=seed)\n",
        "  label = tf.one_hot(label, depth=n_class)\n",
        "  #a=np.array(label)\n",
        "  #label=np.where(a==1)[1]\n",
        "  # Create one continuous latent code\n",
        "  c_1 = tf.random.uniform([batch_size, 1], minval=-1, maxval=1, seed=seed)\n",
        "  return label, c_1, noise\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBwVrYMmrMYU"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "import keras.layers\n",
        "def create_generator_continuous(input_size = 47):\n",
        "    # Build functional API model\n",
        "    # input\n",
        "    input = keras.layers.Input(shape=(input_size,))\n",
        "\n",
        "    # Fully-connected layer.\n",
        "    dense_1 = keras.layers.Dense(units=512, use_bias=False) (input)\n",
        "    bn_1 = keras.layers.BatchNormalization()(dense_1)\n",
        "    act_1 = keras.layers.ReLU()(bn_1)\n",
        "    # Fully-connected layer. The output should be able to reshape into 7x7\n",
        "    dense_2 = keras.layers.Dense(units=128, use_bias=False) (act_1)\n",
        "    bn_2 = keras.layers.BatchNormalization()(dense_2)\n",
        "    act_2 = keras.layers.ReLU()(bn_2)\n",
        "    # Reshape\n",
        "    #reshape = keras.layers.Reshape(target_shape=(512))(act_2)\n",
        "\n",
        "    #nf = n_filters\n",
        "    # First transposed convolutional layer\n",
        "\n",
        "    dense_3 = keras.layers.Dense(units=47, use_bias=False) (act_2)\n",
        "    bn_3 = keras.layers.BatchNormalization()(dense_3)\n",
        "    output = keras.layers.ReLU()(bn_3)\n",
        "\n",
        "    # Number of filters halved after each transposed convolutional layer\n",
        "    #nf = nf//2\n",
        "    # Second transposed convolutional layer\n",
        "    # strides=(2, 2): shape is doubled after the transposed convolutio\n",
        "\n",
        "    # Final transposed convolutional layer: output shape: 28x28x1, tanh activation\n",
        "    #output = keras.layers.Conv2DTranspose(1, kernel_size=(4, 4), strides=(1, 1), \n",
        "                                       #  padding=\"same\", activation=\"tanh\")(act_2)\n",
        "    model = keras.models.Model(inputs=input, outputs=output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH2tcG8Is4pD"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "def create_discriminator_continuous(n_class=6, input_size=47):\n",
        "    # Build functional API model\n",
        "    # Image Input\n",
        "    input = keras.layers.Input(shape=(input_size,))\n",
        "\n",
        "    # Fully-connected layer.\n",
        "    dense_1 = keras.layers.Dense(units=512, use_bias=False) (input)\n",
        "    bn_1 = keras.layers.BatchNormalization()(dense_1)\n",
        "    act_1 = keras.layers.ReLU()(bn_1)\n",
        "\n",
        "    # Fully-connected layer. The output should be able to reshape into 7x7\n",
        "    dense_2 = keras.layers.Dense(units=128, use_bias=False) (act_1)\n",
        "    bn_2 = keras.layers.BatchNormalization()(dense_2)\n",
        "    act_2 = keras.layers.ReLU()(bn_2)\n",
        "    # Reshape\n",
        "    #reshape = keras.layers.Reshape(target_shape=(512))(act_2)\n",
        "\n",
        "    #nf = n_filters\n",
        "    # First transposed convolutional layer\n",
        "\n",
        "    dense_3 = keras.layers.Dense(units=256, use_bias=False) (act_2)\n",
        "    bn_3 = keras.layers.BatchNormalization()(dense_3)\n",
        "    act_3 = keras.layers.ReLU()(bn_3)\n",
        "\n",
        "    d_output = keras.layers.Dense(1, activation='sigmoid')(act_3)\n",
        "\n",
        "    q_dense = keras.layers.Dense(128, use_bias=False)(act_3)\n",
        "    q_bn = keras.layers.BatchNormalization()(q_dense)\n",
        "    q_act = keras.layers.LeakyReLU(alpha=0.1)(q_bn)\n",
        "\n",
        "    # Classification (discrete output)\n",
        "    clf_out = keras.layers.Dense(n_class, activation=\"softmax\")(q_act)\n",
        "\n",
        "    # Gaussian distribution mean (continuous output)\n",
        "    mu = keras.layers.Dense(1)(q_act)\n",
        "\n",
        "    # Gaussian distribution standard deviation (exponential activation to ensure the value is positive)\n",
        "    sigma = keras.layers.Dense(1, activation=lambda x: tf.math.exp(x))(q_act)\n",
        "\n",
        "    # Discriminator model (not compiled)\n",
        "    d_model = keras.models.Model(inputs=input, outputs=d_output)\n",
        "\n",
        "    # Auxiliary model (not compiled)\n",
        "    q_model = keras.models.Model(inputs=input, outputs=[clf_out, mu, sigma])\n",
        "    return d_model, q_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBwfOQjc31Ju"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "fake_batch=[]\n",
        "class InfoGAN_Continuous(keras.Model):\n",
        "    def __init__(self, d_model, g_model, q_model,noise_size, num_classes):\n",
        "        super(InfoGAN_Continuous, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.g_model = g_model\n",
        "        self.q_model = q_model\n",
        "        self.noise_size = noise_size\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, q_optimizer):\n",
        "        super(InfoGAN_Continuous, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.q_optimizer = q_optimizer\n",
        "\n",
        "    def create_gen_input(self, batch_size, noise_size, n_class, seed=None):\n",
        "        # create noise input\n",
        "        noise = tf.random.normal([batch_size, noise_size], seed=seed)\n",
        "        # Create categorical latent code\n",
        "        label = tf.random.uniform([batch_size], minval=0, maxval=6, dtype=tf.int32, seed=seed)\n",
        "        label = tf.one_hot(label, depth=n_class)\n",
        "        # Create one continuous latent code\n",
        "        c_1 = tf.random.uniform([batch_size, 1], minval=-1, maxval=1, seed=seed)\n",
        "        return label, c_1, noise\n",
        "\n",
        "    def concat_inputs(self, input):\n",
        "        concat_input = keras.layers.Concatenate()(input)\n",
        "        return concat_input\n",
        "\n",
        "    def train_step(self, real_image_batch):\n",
        "        # Define loss functions\n",
        "        binary_loss = keras.losses.BinaryCrossentropy()\n",
        "        categorical_loss = keras.losses.CategoricalCrossentropy()\n",
        "        # Half-batch for training discriminator and batch for training generator and auxiliary model\n",
        "        batch = tf.shape(real_image_batch)[0]\n",
        "        # Create generator input \n",
        "        g_label, c_1, g_noise = self.create_gen_input(batch, self.noise_size, self.num_classes, seed=None)\n",
        "        g_input = self.concat_inputs([g_label, c_1, g_noise])\n",
        "        fake_image_batch=[]\n",
        "        with tf.GradientTape() as d_tape: \n",
        "            self.d_model.trainable = True\n",
        "            d_tape.watch(self.d_model.trainable_variables)\n",
        "            # Train discriminator using half batch real images\n",
        "            y_disc_real = tf.ones((batch, 1))\n",
        "            d_real_output = self.d_model(real_image_batch, training=True)\n",
        "            d_loss_real = binary_loss(y_disc_real, d_real_output)\n",
        "            # Train discriminator using half batch fake images     \n",
        "            y_disc_fake = tf.zeros((batch, 1))\n",
        "            # Create fake image batch\n",
        "            fake_image_batch = self.g_model(g_input, training=True)\n",
        "            d_fake_output = self.d_model(fake_image_batch, training=True)\n",
        "            d_loss_fake = binary_loss(y_disc_fake, d_fake_output)\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "        # Calculate gradients\n",
        "        d_gradients = d_tape.gradient(d_loss, self.d_model.trainable_variables)\n",
        "        # Optimize\n",
        "        self.d_optimizer.apply_gradients(zip(d_gradients, self.d_model.trainable_variables))\n",
        "        with tf.GradientTape() as g_tape, tf.GradientTape() as q_tape:\n",
        "            # Create generator input \n",
        "            g_label, c_1, g_noise = self.create_gen_input(batch*2, self.noise_size, self.num_classes, seed=None)\n",
        "            g_input = self.concat_inputs([g_label, c_1, g_noise])\n",
        "            g_tape.watch(self.g_model.trainable_variables)\n",
        "            q_tape.watch(self.q_model.trainable_variables)\n",
        "            # Create fake image batch\n",
        "            fake_image_batch = self.g_model(g_input, training=True)\n",
        "            d_fake_output = self.d_model(fake_image_batch, training=True)\n",
        "            # Generator Image loss\n",
        "            y_gen_fake = tf.ones((batch*2, 1))\n",
        "            g_img_loss = binary_loss(y_gen_fake, d_fake_output)\n",
        "            # Auxiliary loss\n",
        "            cat_output, mu, sigma = self.q_model(fake_image_batch, training=True)\n",
        "            # Categorical loss\n",
        "            cat_loss = categorical_loss(g_label, cat_output)\n",
        "            # Use Gaussian distributions to represent the output\n",
        "            dist = tfp.distributions.Normal(loc=mu, scale=sigma)\n",
        "            # Losses (negative log probability density function as we want to maximize the probability density function)\n",
        "            c_1_loss = tf.reduce_mean(-dist.log_prob(c_1))\n",
        "            # Generator total loss\n",
        "            g_loss = g_img_loss + (cat_loss + 0.1*c_1_loss)\n",
        "            # Auxiliary function loss\n",
        "            q_loss = (cat_loss + 0.1*c_1_loss)\n",
        "        # Calculate gradients\n",
        "        # We do not want to modify the neurons in the discriminator when training the generator and the auxiliary model\n",
        "        self.d_model.trainable=False\n",
        "        g_gradients = g_tape.gradient(g_loss, self.g_model.trainable_variables)\n",
        "        q_gradients = q_tape.gradient(q_loss, self.q_model.trainable_variables)\n",
        "        # Optimize\n",
        "        self.g_optimizer.apply_gradients(zip(g_gradients, self.g_model.trainable_variables))\n",
        "        self.q_optimizer.apply_gradients(zip(q_gradients, self.q_model.trainable_variables))\n",
        "        fake_batch = fake_image_batch\n",
        "        return {\"d_loss_real\": d_loss_real, \"d_loss_fake\": d_loss_fake, \"g_img_loss\": g_img_loss ,\n",
        "                \"cat_loss\": cat_loss, \"c_1_loss\": c_1_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0euruweKj-FW"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "def concat_inputs(input):\n",
        "        concat_input = keras.layers.Concatenate()(input)\n",
        "        return concat_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrFplyrL4mza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a210d8-d543-41de-ad3e-c4b04fd903b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(255, 6)\n",
            "(255, 47)\n",
            "Epoch 1/500\n",
            "8/8 [==============================] - 12s 34ms/step - d_loss_real: 0.5087 - d_loss_fake: 1.0223 - g_img_loss: 0.5458 - cat_loss: 2.1408 - c_1_loss: 3.5354\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 26ms/step - d_loss_real: 0.5332 - d_loss_fake: 0.9093 - g_img_loss: 0.6106 - cat_loss: 2.1560 - c_1_loss: 2.5332\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 25ms/step - d_loss_real: 0.5305 - d_loss_fake: 0.8228 - g_img_loss: 0.6730 - cat_loss: 2.1487 - c_1_loss: 2.1643\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 31ms/step - d_loss_real: 0.5588 - d_loss_fake: 0.7255 - g_img_loss: 0.7461 - cat_loss: 2.0085 - c_1_loss: 2.0820\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.5769 - d_loss_fake: 0.6747 - g_img_loss: 0.7975 - cat_loss: 1.9393 - c_1_loss: 2.2911\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 25ms/step - d_loss_real: 0.6048 - d_loss_fake: 0.6396 - g_img_loss: 0.8473 - cat_loss: 1.9022 - c_1_loss: 1.9169\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.5769 - d_loss_fake: 0.6094 - g_img_loss: 0.8717 - cat_loss: 1.8471 - c_1_loss: 1.8190\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.5361 - d_loss_fake: 0.5875 - g_img_loss: 0.8929 - cat_loss: 1.9013 - c_1_loss: 2.1633\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.5267 - d_loss_fake: 0.5704 - g_img_loss: 0.9098 - cat_loss: 1.8409 - c_1_loss: 1.9230\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.5493 - d_loss_fake: 0.5501 - g_img_loss: 0.9320 - cat_loss: 1.7993 - c_1_loss: 1.7896\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.5287 - d_loss_fake: 0.5418 - g_img_loss: 0.9555 - cat_loss: 1.7947 - c_1_loss: 1.7861\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.5149 - d_loss_fake: 0.5261 - g_img_loss: 0.9693 - cat_loss: 1.7421 - c_1_loss: 1.6749\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.4859 - d_loss_fake: 0.5262 - g_img_loss: 0.9741 - cat_loss: 1.7405 - c_1_loss: 1.8278\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.5007 - d_loss_fake: 0.4972 - g_img_loss: 1.0178 - cat_loss: 1.6652 - c_1_loss: 1.7469\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 23ms/step - d_loss_real: 0.5583 - d_loss_fake: 0.5003 - g_img_loss: 1.0429 - cat_loss: 1.6702 - c_1_loss: 1.7235\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.4724 - d_loss_fake: 0.4882 - g_img_loss: 1.0375 - cat_loss: 1.6209 - c_1_loss: 1.6478\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.4813 - d_loss_fake: 0.4728 - g_img_loss: 1.0585 - cat_loss: 1.6004 - c_1_loss: 1.7116\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 21ms/step - d_loss_real: 0.4224 - d_loss_fake: 0.4681 - g_img_loss: 1.0725 - cat_loss: 1.5309 - c_1_loss: 1.6228\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 22ms/step - d_loss_real: 0.5311 - d_loss_fake: 0.4655 - g_img_loss: 1.0927 - cat_loss: 1.5115 - c_1_loss: 1.7382\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 26ms/step - d_loss_real: 0.4415 - d_loss_fake: 0.4581 - g_img_loss: 1.0829 - cat_loss: 1.4985 - c_1_loss: 1.5669\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 30ms/step - d_loss_real: 0.3935 - d_loss_fake: 0.4476 - g_img_loss: 1.1010 - cat_loss: 1.4418 - c_1_loss: 1.6405\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.4023 - d_loss_fake: 0.4336 - g_img_loss: 1.1361 - cat_loss: 1.3673 - c_1_loss: 1.5650\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 33ms/step - d_loss_real: 0.4022 - d_loss_fake: 0.4183 - g_img_loss: 1.1595 - cat_loss: 1.2790 - c_1_loss: 1.6263\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 36ms/step - d_loss_real: 0.4992 - d_loss_fake: 0.4075 - g_img_loss: 1.1977 - cat_loss: 1.2983 - c_1_loss: 1.5416\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 26ms/step - d_loss_real: 0.3492 - d_loss_fake: 0.3978 - g_img_loss: 1.1924 - cat_loss: 1.2014 - c_1_loss: 1.5819\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 31ms/step - d_loss_real: 0.4833 - d_loss_fake: 0.3996 - g_img_loss: 1.2242 - cat_loss: 1.0478 - c_1_loss: 1.5778\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.3905 - d_loss_fake: 0.3923 - g_img_loss: 1.2013 - cat_loss: 1.0393 - c_1_loss: 1.5367\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.3585 - d_loss_fake: 0.3931 - g_img_loss: 1.2353 - cat_loss: 0.9319 - c_1_loss: 1.4918\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.4099 - d_loss_fake: 0.3712 - g_img_loss: 1.2552 - cat_loss: 0.8463 - c_1_loss: 1.5874\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.3289 - d_loss_fake: 0.3606 - g_img_loss: 1.2691 - cat_loss: 0.7985 - c_1_loss: 1.6265\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 37ms/step - d_loss_real: 0.3802 - d_loss_fake: 0.3556 - g_img_loss: 1.2954 - cat_loss: 0.7388 - c_1_loss: 1.4459\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.3181 - d_loss_fake: 0.3551 - g_img_loss: 1.3167 - cat_loss: 0.6810 - c_1_loss: 1.4948\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.3305 - d_loss_fake: 0.3349 - g_img_loss: 1.3372 - cat_loss: 0.5742 - c_1_loss: 1.5405\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 25ms/step - d_loss_real: 0.3702 - d_loss_fake: 0.3304 - g_img_loss: 1.3665 - cat_loss: 0.5553 - c_1_loss: 1.5122\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 32ms/step - d_loss_real: 0.2926 - d_loss_fake: 0.3230 - g_img_loss: 1.3900 - cat_loss: 0.4930 - c_1_loss: 1.5319\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 25ms/step - d_loss_real: 0.3199 - d_loss_fake: 0.3167 - g_img_loss: 1.4134 - cat_loss: 0.4411 - c_1_loss: 1.4429\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 25ms/step - d_loss_real: 0.3273 - d_loss_fake: 0.2955 - g_img_loss: 1.4690 - cat_loss: 0.4383 - c_1_loss: 1.4135\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.3858 - d_loss_fake: 0.3073 - g_img_loss: 1.4614 - cat_loss: 0.3979 - c_1_loss: 1.4056\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.3489 - d_loss_fake: 0.3045 - g_img_loss: 1.4413 - cat_loss: 0.3306 - c_1_loss: 1.4502\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.3394 - d_loss_fake: 0.3142 - g_img_loss: 1.4275 - cat_loss: 0.3223 - c_1_loss: 1.4628\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 24ms/step - d_loss_real: 0.3181 - d_loss_fake: 0.3123 - g_img_loss: 1.4241 - cat_loss: 0.3102 - c_1_loss: 1.4262\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.3578 - d_loss_fake: 0.3139 - g_img_loss: 1.4523 - cat_loss: 0.2405 - c_1_loss: 1.4198\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 36ms/step - d_loss_real: 0.3044 - d_loss_fake: 0.2949 - g_img_loss: 1.4751 - cat_loss: 0.2660 - c_1_loss: 1.3918\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 40ms/step - d_loss_real: 0.3243 - d_loss_fake: 0.2997 - g_img_loss: 1.4747 - cat_loss: 0.2418 - c_1_loss: 1.3508\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 30ms/step - d_loss_real: 0.3731 - d_loss_fake: 0.2912 - g_img_loss: 1.4878 - cat_loss: 0.1849 - c_1_loss: 1.3511\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.3413 - d_loss_fake: 0.2918 - g_img_loss: 1.4514 - cat_loss: 0.1791 - c_1_loss: 1.3483\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 23ms/step - d_loss_real: 0.2941 - d_loss_fake: 0.2930 - g_img_loss: 1.4661 - cat_loss: 0.1628 - c_1_loss: 1.2914\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 38ms/step - d_loss_real: 0.2566 - d_loss_fake: 0.2947 - g_img_loss: 1.4803 - cat_loss: 0.1699 - c_1_loss: 1.2847\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 30ms/step - d_loss_real: 0.2298 - d_loss_fake: 0.2749 - g_img_loss: 1.5499 - cat_loss: 0.1528 - c_1_loss: 1.2851\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.2171 - d_loss_fake: 0.2579 - g_img_loss: 1.5949 - cat_loss: 0.1453 - c_1_loss: 1.2534\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.3297 - d_loss_fake: 0.2388 - g_img_loss: 1.6523 - cat_loss: 0.1600 - c_1_loss: 1.2374\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.2810 - d_loss_fake: 0.2378 - g_img_loss: 1.6697 - cat_loss: 0.1259 - c_1_loss: 1.2446\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 24ms/step - d_loss_real: 0.3386 - d_loss_fake: 0.2433 - g_img_loss: 1.6290 - cat_loss: 0.1187 - c_1_loss: 1.2729\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 26ms/step - d_loss_real: 0.2001 - d_loss_fake: 0.2476 - g_img_loss: 1.6377 - cat_loss: 0.1150 - c_1_loss: 1.2516\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.3074 - d_loss_fake: 0.2323 - g_img_loss: 1.6586 - cat_loss: 0.1023 - c_1_loss: 1.2229\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 32ms/step - d_loss_real: 0.2704 - d_loss_fake: 0.2359 - g_img_loss: 1.6476 - cat_loss: 0.1011 - c_1_loss: 1.1930\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.2837 - d_loss_fake: 0.2429 - g_img_loss: 1.6510 - cat_loss: 0.0998 - c_1_loss: 1.1929\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.2506 - d_loss_fake: 0.2425 - g_img_loss: 1.6465 - cat_loss: 0.0921 - c_1_loss: 1.1846\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 33ms/step - d_loss_real: 0.2362 - d_loss_fake: 0.2386 - g_img_loss: 1.6640 - cat_loss: 0.1087 - c_1_loss: 1.2259\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.2346 - d_loss_fake: 0.2316 - g_img_loss: 1.6844 - cat_loss: 0.1105 - c_1_loss: 1.1708\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 30ms/step - d_loss_real: 0.2222 - d_loss_fake: 0.2294 - g_img_loss: 1.6995 - cat_loss: 0.0917 - c_1_loss: 1.2033\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 33ms/step - d_loss_real: 0.1968 - d_loss_fake: 0.2180 - g_img_loss: 1.7350 - cat_loss: 0.0811 - c_1_loss: 1.1599\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.2680 - d_loss_fake: 0.2097 - g_img_loss: 1.7603 - cat_loss: 0.0919 - c_1_loss: 1.1808\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.3111 - d_loss_fake: 0.2107 - g_img_loss: 1.7526 - cat_loss: 0.0788 - c_1_loss: 1.1269\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.1877 - d_loss_fake: 0.2197 - g_img_loss: 1.7630 - cat_loss: 0.0842 - c_1_loss: 1.1137\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.2279 - d_loss_fake: 0.2022 - g_img_loss: 1.7774 - cat_loss: 0.0847 - c_1_loss: 1.0960\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.2588 - d_loss_fake: 0.2089 - g_img_loss: 1.7802 - cat_loss: 0.0859 - c_1_loss: 1.0925\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 30ms/step - d_loss_real: 0.2076 - d_loss_fake: 0.2150 - g_img_loss: 1.7793 - cat_loss: 0.0805 - c_1_loss: 1.0913\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 30ms/step - d_loss_real: 0.1444 - d_loss_fake: 0.2104 - g_img_loss: 1.8148 - cat_loss: 0.0661 - c_1_loss: 1.1424\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 26ms/step - d_loss_real: 0.1659 - d_loss_fake: 0.1901 - g_img_loss: 1.8526 - cat_loss: 0.0978 - c_1_loss: 1.1430\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 24ms/step - d_loss_real: 0.1779 - d_loss_fake: 0.1837 - g_img_loss: 1.9081 - cat_loss: 0.0767 - c_1_loss: 1.1109\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 29ms/step - d_loss_real: 0.3332 - d_loss_fake: 0.1813 - g_img_loss: 1.9384 - cat_loss: 0.1082 - c_1_loss: 1.1431\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.2326 - d_loss_fake: 0.1814 - g_img_loss: 1.9048 - cat_loss: 0.0753 - c_1_loss: 1.0693\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 27ms/step - d_loss_real: 0.1605 - d_loss_fake: 0.1897 - g_img_loss: 1.8846 - cat_loss: 0.0826 - c_1_loss: 1.1169\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 35ms/step - d_loss_real: 0.2676 - d_loss_fake: 0.1894 - g_img_loss: 1.8463 - cat_loss: 0.0853 - c_1_loss: 1.0718\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 26ms/step - d_loss_real: 0.2086 - d_loss_fake: 0.1882 - g_img_loss: 1.8522 - cat_loss: 0.1085 - c_1_loss: 1.0838\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 33ms/step - d_loss_real: 0.2311 - d_loss_fake: 0.1961 - g_img_loss: 1.8275 - cat_loss: 0.0845 - c_1_loss: 1.0571\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.1579 - d_loss_fake: 0.2038 - g_img_loss: 1.8095 - cat_loss: 0.1167 - c_1_loss: 1.1039\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 21ms/step - d_loss_real: 0.2313 - d_loss_fake: 0.1920 - g_img_loss: 1.8285 - cat_loss: 0.0926 - c_1_loss: 1.0583\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 28ms/step - d_loss_real: 0.1565 - d_loss_fake: 0.1987 - g_img_loss: 1.8860 - cat_loss: 0.1102 - c_1_loss: 1.0930\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 23ms/step - d_loss_real: 0.1893 - d_loss_fake: 0.1856 - g_img_loss: 1.9318 - cat_loss: 0.1266 - c_1_loss: 1.0076\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 24ms/step - d_loss_real: 0.1968 - d_loss_fake: 0.1817 - g_img_loss: 1.9648 - cat_loss: 0.0888 - c_1_loss: 1.0567\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 35ms/step - d_loss_real: 0.1736 - d_loss_fake: 0.1691 - g_img_loss: 1.9793 - cat_loss: 0.1212 - c_1_loss: 1.0495\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1408 - d_loss_fake: 0.1759 - g_img_loss: 1.9905 - cat_loss: 0.1301 - c_1_loss: 1.1027\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.2124 - d_loss_fake: 0.1671 - g_img_loss: 2.0273 - cat_loss: 0.1821 - c_1_loss: 1.0369\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1423 - d_loss_fake: 0.1706 - g_img_loss: 2.0212 - cat_loss: 0.0946 - c_1_loss: 0.9667\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1076 - d_loss_fake: 0.1621 - g_img_loss: 2.0388 - cat_loss: 0.1176 - c_1_loss: 1.0583\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.2158 - d_loss_fake: 0.1529 - g_img_loss: 2.0747 - cat_loss: 0.1143 - c_1_loss: 1.0565\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.2139 - d_loss_fake: 0.1579 - g_img_loss: 2.0777 - cat_loss: 0.1154 - c_1_loss: 1.0861\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1744 - d_loss_fake: 0.1582 - g_img_loss: 2.0689 - cat_loss: 0.1357 - c_1_loss: 1.0679\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1572 - d_loss_fake: 0.1601 - g_img_loss: 2.0939 - cat_loss: 0.1429 - c_1_loss: 1.0829\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1871 - d_loss_fake: 0.1561 - g_img_loss: 2.0376 - cat_loss: 0.1405 - c_1_loss: 1.0251\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1356 - d_loss_fake: 0.1531 - g_img_loss: 2.0747 - cat_loss: 0.1529 - c_1_loss: 1.0523\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1084 - d_loss_fake: 0.1510 - g_img_loss: 2.0960 - cat_loss: 0.1368 - c_1_loss: 1.0243\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1433 - d_loss_fake: 0.1492 - g_img_loss: 2.1618 - cat_loss: 0.1428 - c_1_loss: 1.0163\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1391 - d_loss_fake: 0.1452 - g_img_loss: 2.1592 - cat_loss: 0.1516 - c_1_loss: 1.0459\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1268 - d_loss_fake: 0.1411 - g_img_loss: 2.1565 - cat_loss: 0.1607 - c_1_loss: 1.0458\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.1347 - d_loss_fake: 0.1421 - g_img_loss: 2.2305 - cat_loss: 0.1011 - c_1_loss: 1.0383\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1945 - d_loss_fake: 0.1386 - g_img_loss: 2.2479 - cat_loss: 0.1213 - c_1_loss: 0.9717\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1525 - d_loss_fake: 0.1348 - g_img_loss: 2.2715 - cat_loss: 0.1463 - c_1_loss: 1.0023\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1279 - d_loss_fake: 0.1319 - g_img_loss: 2.2309 - cat_loss: 0.1573 - c_1_loss: 1.0091\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1237 - d_loss_fake: 0.1349 - g_img_loss: 2.2872 - cat_loss: 0.1396 - c_1_loss: 1.0437\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1276 - d_loss_fake: 0.1337 - g_img_loss: 2.2832 - cat_loss: 0.1376 - c_1_loss: 0.9797\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1271 - d_loss_fake: 0.1251 - g_img_loss: 2.2751 - cat_loss: 0.1598 - c_1_loss: 1.0185\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1569 - d_loss_fake: 0.1299 - g_img_loss: 2.2807 - cat_loss: 0.1684 - c_1_loss: 1.0025\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1428 - d_loss_fake: 0.1243 - g_img_loss: 2.2776 - cat_loss: 0.1778 - c_1_loss: 1.0209\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1993 - d_loss_fake: 0.1436 - g_img_loss: 2.2208 - cat_loss: 0.1474 - c_1_loss: 0.9829\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1240 - d_loss_fake: 0.1357 - g_img_loss: 2.2251 - cat_loss: 0.1678 - c_1_loss: 0.9724\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1202 - d_loss_fake: 0.1298 - g_img_loss: 2.2269 - cat_loss: 0.1856 - c_1_loss: 1.0401\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.2115 - d_loss_fake: 0.1315 - g_img_loss: 2.2577 - cat_loss: 0.1355 - c_1_loss: 0.9474\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1470 - d_loss_fake: 0.1273 - g_img_loss: 2.2665 - cat_loss: 0.1578 - c_1_loss: 1.0134\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1582 - d_loss_fake: 0.1332 - g_img_loss: 2.2826 - cat_loss: 0.1352 - c_1_loss: 0.9771\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1288 - d_loss_fake: 0.1235 - g_img_loss: 2.3043 - cat_loss: 0.1497 - c_1_loss: 0.9764\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.2959 - d_loss_fake: 0.1309 - g_img_loss: 2.2399 - cat_loss: 0.1600 - c_1_loss: 0.9662\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1181 - d_loss_fake: 0.1462 - g_img_loss: 2.2170 - cat_loss: 0.1215 - c_1_loss: 0.9823\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1169 - d_loss_fake: 0.1397 - g_img_loss: 2.2306 - cat_loss: 0.1508 - c_1_loss: 0.9951\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1420 - d_loss_fake: 0.1426 - g_img_loss: 2.2583 - cat_loss: 0.1482 - c_1_loss: 0.9449\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1153 - d_loss_fake: 0.1381 - g_img_loss: 2.2758 - cat_loss: 0.1260 - c_1_loss: 0.9898\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0943 - d_loss_fake: 0.1224 - g_img_loss: 2.3204 - cat_loss: 0.1524 - c_1_loss: 0.9844\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1423 - d_loss_fake: 0.1263 - g_img_loss: 2.3441 - cat_loss: 0.1468 - c_1_loss: 0.9954\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1092 - d_loss_fake: 0.1213 - g_img_loss: 2.3813 - cat_loss: 0.1402 - c_1_loss: 0.9851\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.2136 - d_loss_fake: 0.1138 - g_img_loss: 2.3920 - cat_loss: 0.1564 - c_1_loss: 0.9279\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.1768 - d_loss_fake: 0.1262 - g_img_loss: 2.3021 - cat_loss: 0.1691 - c_1_loss: 0.9956\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1065 - d_loss_fake: 0.1381 - g_img_loss: 2.2512 - cat_loss: 0.1416 - c_1_loss: 0.9504\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1247 - d_loss_fake: 0.1320 - g_img_loss: 2.2759 - cat_loss: 0.2026 - c_1_loss: 0.9642\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1023 - d_loss_fake: 0.1314 - g_img_loss: 2.3295 - cat_loss: 0.1396 - c_1_loss: 0.8777\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1368 - d_loss_fake: 0.1215 - g_img_loss: 2.3635 - cat_loss: 0.1308 - c_1_loss: 0.9374\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1316 - d_loss_fake: 0.1243 - g_img_loss: 2.3682 - cat_loss: 0.1111 - c_1_loss: 0.9241\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1116 - d_loss_fake: 0.1242 - g_img_loss: 2.3666 - cat_loss: 0.1347 - c_1_loss: 0.8989\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1027 - d_loss_fake: 0.1184 - g_img_loss: 2.3770 - cat_loss: 0.1592 - c_1_loss: 0.8918\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1080 - d_loss_fake: 0.1142 - g_img_loss: 2.3645 - cat_loss: 0.1983 - c_1_loss: 0.9442\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1640 - d_loss_fake: 0.1114 - g_img_loss: 2.4150 - cat_loss: 0.1320 - c_1_loss: 0.8665\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0922 - d_loss_fake: 0.1090 - g_img_loss: 2.4373 - cat_loss: 0.1490 - c_1_loss: 0.8898\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1106 - d_loss_fake: 0.1087 - g_img_loss: 2.4265 - cat_loss: 0.1435 - c_1_loss: 0.8797\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1146 - d_loss_fake: 0.1153 - g_img_loss: 2.4913 - cat_loss: 0.1754 - c_1_loss: 0.9384\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.1064 - d_loss_fake: 0.1014 - g_img_loss: 2.5143 - cat_loss: 0.1681 - c_1_loss: 0.9828\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0986 - d_loss_fake: 0.1199 - g_img_loss: 2.5556 - cat_loss: 0.1672 - c_1_loss: 0.8987\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1169 - d_loss_fake: 0.1001 - g_img_loss: 2.5363 - cat_loss: 0.1991 - c_1_loss: 0.8825\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0833 - d_loss_fake: 0.1053 - g_img_loss: 2.5974 - cat_loss: 0.1542 - c_1_loss: 0.9128\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1245 - d_loss_fake: 0.0883 - g_img_loss: 2.6015 - cat_loss: 0.1623 - c_1_loss: 0.9257\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1455 - d_loss_fake: 0.1058 - g_img_loss: 2.5377 - cat_loss: 0.1411 - c_1_loss: 0.8989\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1034 - d_loss_fake: 0.1044 - g_img_loss: 2.4587 - cat_loss: 0.1725 - c_1_loss: 0.8795\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0762 - d_loss_fake: 0.1144 - g_img_loss: 2.4782 - cat_loss: 0.1293 - c_1_loss: 0.9003\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1165 - d_loss_fake: 0.1035 - g_img_loss: 2.5129 - cat_loss: 0.1610 - c_1_loss: 0.8740\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0848 - d_loss_fake: 0.0975 - g_img_loss: 2.5818 - cat_loss: 0.1596 - c_1_loss: 0.8712\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1332 - d_loss_fake: 0.1004 - g_img_loss: 2.5618 - cat_loss: 0.1659 - c_1_loss: 0.9038\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1400 - d_loss_fake: 0.0941 - g_img_loss: 2.5453 - cat_loss: 0.1463 - c_1_loss: 0.8502\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1357 - d_loss_fake: 0.1022 - g_img_loss: 2.4578 - cat_loss: 0.1631 - c_1_loss: 0.8636\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1516 - d_loss_fake: 0.0988 - g_img_loss: 2.5020 - cat_loss: 0.1349 - c_1_loss: 0.8208\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0764 - d_loss_fake: 0.1132 - g_img_loss: 2.4419 - cat_loss: 0.1833 - c_1_loss: 0.8682\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0986 - d_loss_fake: 0.1020 - g_img_loss: 2.4746 - cat_loss: 0.1694 - c_1_loss: 0.8236\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1189 - d_loss_fake: 0.1054 - g_img_loss: 2.5277 - cat_loss: 0.1519 - c_1_loss: 0.8291\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1032 - d_loss_fake: 0.1019 - g_img_loss: 2.5029 - cat_loss: 0.1739 - c_1_loss: 0.8633\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1441 - d_loss_fake: 0.1060 - g_img_loss: 2.5011 - cat_loss: 0.1448 - c_1_loss: 0.8460\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1025 - d_loss_fake: 0.0939 - g_img_loss: 2.4937 - cat_loss: 0.1412 - c_1_loss: 0.8674\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0868 - d_loss_fake: 0.0932 - g_img_loss: 2.5156 - cat_loss: 0.1185 - c_1_loss: 0.8204\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0712 - d_loss_fake: 0.1075 - g_img_loss: 2.5460 - cat_loss: 0.1124 - c_1_loss: 0.8545\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0880 - d_loss_fake: 0.0911 - g_img_loss: 2.6062 - cat_loss: 0.1096 - c_1_loss: 0.8160\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.1328 - d_loss_fake: 0.0956 - g_img_loss: 2.5325 - cat_loss: 0.1342 - c_1_loss: 0.8496\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0722 - d_loss_fake: 0.0991 - g_img_loss: 2.5001 - cat_loss: 0.1083 - c_1_loss: 0.8619\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0969 - d_loss_fake: 0.0868 - g_img_loss: 2.5609 - cat_loss: 0.1429 - c_1_loss: 0.8404\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1453 - d_loss_fake: 0.0857 - g_img_loss: 2.6247 - cat_loss: 0.1354 - c_1_loss: 0.8203\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1132 - d_loss_fake: 0.0984 - g_img_loss: 2.5796 - cat_loss: 0.1583 - c_1_loss: 0.8015\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 13ms/step - d_loss_real: 0.0965 - d_loss_fake: 0.1037 - g_img_loss: 2.5393 - cat_loss: 0.1530 - c_1_loss: 0.8398\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0966 - d_loss_fake: 0.1018 - g_img_loss: 2.4200 - cat_loss: 0.1341 - c_1_loss: 0.8511\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0728 - d_loss_fake: 0.0983 - g_img_loss: 2.5199 - cat_loss: 0.1382 - c_1_loss: 0.8499\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0870 - d_loss_fake: 0.0857 - g_img_loss: 2.6831 - cat_loss: 0.1314 - c_1_loss: 0.8967\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1086 - d_loss_fake: 0.0842 - g_img_loss: 2.6733 - cat_loss: 0.1369 - c_1_loss: 0.8326\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0864 - d_loss_fake: 0.0874 - g_img_loss: 2.7011 - cat_loss: 0.1043 - c_1_loss: 0.8358\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0735 - d_loss_fake: 0.0848 - g_img_loss: 2.6667 - cat_loss: 0.1231 - c_1_loss: 0.8419\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0980 - d_loss_fake: 0.0901 - g_img_loss: 2.6589 - cat_loss: 0.1200 - c_1_loss: 0.8172\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0510 - d_loss_fake: 0.0815 - g_img_loss: 2.6969 - cat_loss: 0.1557 - c_1_loss: 0.8349\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0613 - d_loss_fake: 0.0814 - g_img_loss: 2.7738 - cat_loss: 0.1262 - c_1_loss: 0.7930\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1827 - d_loss_fake: 0.0837 - g_img_loss: 2.7943 - cat_loss: 0.1150 - c_1_loss: 0.7567\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1230 - d_loss_fake: 0.0812 - g_img_loss: 2.7424 - cat_loss: 0.0875 - c_1_loss: 0.8127\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1501 - d_loss_fake: 0.0877 - g_img_loss: 2.6426 - cat_loss: 0.1181 - c_1_loss: 0.8380\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1128 - d_loss_fake: 0.0957 - g_img_loss: 2.3935 - cat_loss: 0.1306 - c_1_loss: 0.7578\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1184 - d_loss_fake: 0.0932 - g_img_loss: 2.4611 - cat_loss: 0.1297 - c_1_loss: 0.7726\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1521 - d_loss_fake: 0.1027 - g_img_loss: 2.3975 - cat_loss: 0.1466 - c_1_loss: 0.8071\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0608 - d_loss_fake: 0.1063 - g_img_loss: 2.3894 - cat_loss: 0.1461 - c_1_loss: 0.8117\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1193 - d_loss_fake: 0.1139 - g_img_loss: 2.4468 - cat_loss: 0.1577 - c_1_loss: 0.7598\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0841 - d_loss_fake: 0.0936 - g_img_loss: 2.6607 - cat_loss: 0.1120 - c_1_loss: 0.8895\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1114 - d_loss_fake: 0.0848 - g_img_loss: 2.6946 - cat_loss: 0.1460 - c_1_loss: 0.7752\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0803 - d_loss_fake: 0.0882 - g_img_loss: 2.6196 - cat_loss: 0.1398 - c_1_loss: 0.7723\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0657 - d_loss_fake: 0.0926 - g_img_loss: 2.6123 - cat_loss: 0.1363 - c_1_loss: 0.7899\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0863 - d_loss_fake: 0.0888 - g_img_loss: 2.6927 - cat_loss: 0.1526 - c_1_loss: 0.7624\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0810 - d_loss_fake: 0.0932 - g_img_loss: 2.6673 - cat_loss: 0.0893 - c_1_loss: 0.7872\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0842 - d_loss_fake: 0.0768 - g_img_loss: 2.7751 - cat_loss: 0.1284 - c_1_loss: 0.8136\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1033 - d_loss_fake: 0.0863 - g_img_loss: 2.7113 - cat_loss: 0.1588 - c_1_loss: 0.8245\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0630 - d_loss_fake: 0.0853 - g_img_loss: 2.7367 - cat_loss: 0.1594 - c_1_loss: 0.7269\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1620 - d_loss_fake: 0.0779 - g_img_loss: 2.8139 - cat_loss: 0.1482 - c_1_loss: 0.8163\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0994 - d_loss_fake: 0.0808 - g_img_loss: 2.7067 - cat_loss: 0.1240 - c_1_loss: 0.7593\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0735 - d_loss_fake: 0.0908 - g_img_loss: 2.5882 - cat_loss: 0.1162 - c_1_loss: 0.8227\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1066 - d_loss_fake: 0.0924 - g_img_loss: 2.6964 - cat_loss: 0.1330 - c_1_loss: 0.8150\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1010 - d_loss_fake: 0.0837 - g_img_loss: 2.6415 - cat_loss: 0.1268 - c_1_loss: 0.8332\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1496 - d_loss_fake: 0.0998 - g_img_loss: 2.5324 - cat_loss: 0.1245 - c_1_loss: 0.7898\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0879 - d_loss_fake: 0.1086 - g_img_loss: 2.6331 - cat_loss: 0.1329 - c_1_loss: 0.8078\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0560 - d_loss_fake: 0.0923 - g_img_loss: 2.5203 - cat_loss: 0.1651 - c_1_loss: 0.7600\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0610 - d_loss_fake: 0.0834 - g_img_loss: 2.7555 - cat_loss: 0.1532 - c_1_loss: 0.8486\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.2381 - d_loss_fake: 0.0789 - g_img_loss: 2.7853 - cat_loss: 0.1238 - c_1_loss: 0.8661\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0881 - d_loss_fake: 0.1120 - g_img_loss: 2.6480 - cat_loss: 0.2153 - c_1_loss: 0.8006\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0673 - d_loss_fake: 0.0862 - g_img_loss: 2.7261 - cat_loss: 0.1414 - c_1_loss: 0.7869\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0922 - d_loss_fake: 0.0901 - g_img_loss: 2.7432 - cat_loss: 0.1458 - c_1_loss: 0.8856\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0578 - d_loss_fake: 0.0762 - g_img_loss: 2.7711 - cat_loss: 0.1354 - c_1_loss: 0.7936\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0994 - d_loss_fake: 0.0808 - g_img_loss: 2.8019 - cat_loss: 0.1675 - c_1_loss: 0.7886\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0448 - d_loss_fake: 0.0795 - g_img_loss: 2.8027 - cat_loss: 0.1319 - c_1_loss: 0.8212\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1001 - d_loss_fake: 0.0749 - g_img_loss: 2.9104 - cat_loss: 0.1593 - c_1_loss: 0.7892\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1409 - d_loss_fake: 0.0763 - g_img_loss: 2.7014 - cat_loss: 0.1399 - c_1_loss: 0.8162\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1153 - d_loss_fake: 0.0997 - g_img_loss: 2.3924 - cat_loss: 0.1441 - c_1_loss: 0.7852\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1778 - d_loss_fake: 0.0955 - g_img_loss: 2.6099 - cat_loss: 0.1913 - c_1_loss: 0.8857\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0878 - d_loss_fake: 0.1067 - g_img_loss: 2.7148 - cat_loss: 0.1638 - c_1_loss: 0.8346\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0749 - d_loss_fake: 0.1015 - g_img_loss: 2.6867 - cat_loss: 0.1528 - c_1_loss: 0.8657\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0519 - d_loss_fake: 0.0792 - g_img_loss: 2.9445 - cat_loss: 0.1578 - c_1_loss: 0.8618\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1427 - d_loss_fake: 0.0703 - g_img_loss: 2.7355 - cat_loss: 0.1566 - c_1_loss: 0.8860\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0608 - d_loss_fake: 0.0963 - g_img_loss: 2.6168 - cat_loss: 0.1363 - c_1_loss: 0.7994\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0848 - d_loss_fake: 0.0874 - g_img_loss: 2.6506 - cat_loss: 0.1856 - c_1_loss: 0.8629\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1103 - d_loss_fake: 0.0980 - g_img_loss: 2.7565 - cat_loss: 0.1878 - c_1_loss: 0.8474\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.1104 - d_loss_fake: 0.0975 - g_img_loss: 2.7976 - cat_loss: 0.2124 - c_1_loss: 0.8707\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0965 - d_loss_fake: 0.0756 - g_img_loss: 2.7631 - cat_loss: 0.1791 - c_1_loss: 0.9194\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1131 - d_loss_fake: 0.0989 - g_img_loss: 2.6655 - cat_loss: 0.1485 - c_1_loss: 0.9029\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1603 - d_loss_fake: 0.0941 - g_img_loss: 2.6528 - cat_loss: 0.1465 - c_1_loss: 0.9218\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1705 - d_loss_fake: 0.0997 - g_img_loss: 2.4992 - cat_loss: 0.1846 - c_1_loss: 0.9487\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0670 - d_loss_fake: 0.1181 - g_img_loss: 2.6984 - cat_loss: 0.2950 - c_1_loss: 0.8828\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.2076 - d_loss_fake: 0.1061 - g_img_loss: 2.6028 - cat_loss: 0.1763 - c_1_loss: 0.9214\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0884 - d_loss_fake: 0.1926 - g_img_loss: 2.2528 - cat_loss: 0.1776 - c_1_loss: 0.9145\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1098 - d_loss_fake: 0.0887 - g_img_loss: 2.8319 - cat_loss: 0.2356 - c_1_loss: 0.9988\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1276 - d_loss_fake: 0.0925 - g_img_loss: 2.6970 - cat_loss: 0.2012 - c_1_loss: 0.9097\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1467 - d_loss_fake: 0.1217 - g_img_loss: 2.4844 - cat_loss: 0.2176 - c_1_loss: 0.9052\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0783 - d_loss_fake: 0.1237 - g_img_loss: 2.5737 - cat_loss: 0.1950 - c_1_loss: 0.9764\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0930 - d_loss_fake: 0.0964 - g_img_loss: 2.7702 - cat_loss: 0.1831 - c_1_loss: 0.9393\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0972 - d_loss_fake: 0.0883 - g_img_loss: 2.5732 - cat_loss: 0.1693 - c_1_loss: 0.9024\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0848 - d_loss_fake: 0.1054 - g_img_loss: 2.5125 - cat_loss: 0.1409 - c_1_loss: 0.9289\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0948 - d_loss_fake: 0.1273 - g_img_loss: 2.5267 - cat_loss: 0.1748 - c_1_loss: 0.9544\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0918 - d_loss_fake: 0.0930 - g_img_loss: 2.9121 - cat_loss: 0.1021 - c_1_loss: 0.9365\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.2216 - d_loss_fake: 0.1239 - g_img_loss: 2.5890 - cat_loss: 0.1325 - c_1_loss: 0.9804\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.2316 - d_loss_fake: 0.1459 - g_img_loss: 2.1813 - cat_loss: 0.1507 - c_1_loss: 0.9393\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1588 - d_loss_fake: 0.1681 - g_img_loss: 2.1278 - cat_loss: 0.1678 - c_1_loss: 0.9421\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1720 - d_loss_fake: 0.1111 - g_img_loss: 2.3924 - cat_loss: 0.1971 - c_1_loss: 0.9319\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0934 - d_loss_fake: 0.1262 - g_img_loss: 2.4893 - cat_loss: 0.2102 - c_1_loss: 0.9900\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1797 - d_loss_fake: 0.1153 - g_img_loss: 2.4478 - cat_loss: 0.1899 - c_1_loss: 0.9346\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1068 - d_loss_fake: 0.1546 - g_img_loss: 2.1965 - cat_loss: 0.1875 - c_1_loss: 1.0057\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1293 - d_loss_fake: 0.1473 - g_img_loss: 2.3461 - cat_loss: 0.1837 - c_1_loss: 0.9692\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1384 - d_loss_fake: 0.1102 - g_img_loss: 2.4528 - cat_loss: 0.2841 - c_1_loss: 0.9475\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1884 - d_loss_fake: 0.2013 - g_img_loss: 2.0475 - cat_loss: 0.3036 - c_1_loss: 1.0145\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1492 - d_loss_fake: 0.1683 - g_img_loss: 2.4886 - cat_loss: 0.2357 - c_1_loss: 1.0119\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1095 - d_loss_fake: 0.1313 - g_img_loss: 2.4564 - cat_loss: 0.2136 - c_1_loss: 1.0056\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.2087 - d_loss_fake: 0.1153 - g_img_loss: 2.3320 - cat_loss: 0.2013 - c_1_loss: 0.9604\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0818 - d_loss_fake: 0.1630 - g_img_loss: 2.4801 - cat_loss: 0.2300 - c_1_loss: 0.9566\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1602 - d_loss_fake: 0.0953 - g_img_loss: 2.7251 - cat_loss: 0.2464 - c_1_loss: 0.9831\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1932 - d_loss_fake: 0.1749 - g_img_loss: 2.0029 - cat_loss: 0.2680 - c_1_loss: 0.9377\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1672 - d_loss_fake: 0.1228 - g_img_loss: 2.3501 - cat_loss: 0.2301 - c_1_loss: 0.9386\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1255 - d_loss_fake: 0.1190 - g_img_loss: 2.1878 - cat_loss: 0.4126 - c_1_loss: 1.0203\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.1334 - d_loss_fake: 0.1645 - g_img_loss: 2.5573 - cat_loss: 0.2863 - c_1_loss: 0.9784\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0974 - d_loss_fake: 0.0953 - g_img_loss: 2.4569 - cat_loss: 0.1891 - c_1_loss: 0.9801\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1182 - d_loss_fake: 0.1604 - g_img_loss: 1.9164 - cat_loss: 0.1556 - c_1_loss: 0.9950\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1785 - d_loss_fake: 0.1224 - g_img_loss: 2.8175 - cat_loss: 0.2059 - c_1_loss: 0.9564\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1205 - d_loss_fake: 0.1021 - g_img_loss: 2.5560 - cat_loss: 0.1884 - c_1_loss: 0.9402\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.1134 - d_loss_fake: 0.1442 - g_img_loss: 2.3170 - cat_loss: 0.2068 - c_1_loss: 0.9644\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0879 - d_loss_fake: 0.0885 - g_img_loss: 2.7216 - cat_loss: 0.1648 - c_1_loss: 0.9300\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1653 - d_loss_fake: 0.1229 - g_img_loss: 2.4595 - cat_loss: 0.1886 - c_1_loss: 0.8715\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0907 - d_loss_fake: 0.1310 - g_img_loss: 2.4361 - cat_loss: 0.1508 - c_1_loss: 0.9332\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1311 - d_loss_fake: 0.1091 - g_img_loss: 2.5421 - cat_loss: 0.1287 - c_1_loss: 0.9126\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.1218 - d_loss_fake: 0.1940 - g_img_loss: 2.1639 - cat_loss: 0.2799 - c_1_loss: 0.9477\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.2724 - d_loss_fake: 0.1271 - g_img_loss: 2.5348 - cat_loss: 0.2083 - c_1_loss: 0.9556\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0942 - d_loss_fake: 0.1238 - g_img_loss: 2.3904 - cat_loss: 0.1123 - c_1_loss: 0.9480\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0734 - d_loss_fake: 0.0928 - g_img_loss: 2.6656 - cat_loss: 0.1362 - c_1_loss: 0.8901\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1008 - d_loss_fake: 0.1009 - g_img_loss: 2.4692 - cat_loss: 0.1335 - c_1_loss: 0.9506\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.1179 - d_loss_fake: 0.1150 - g_img_loss: 2.6069 - cat_loss: 0.1609 - c_1_loss: 0.9597\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1076 - d_loss_fake: 0.0686 - g_img_loss: 2.7030 - cat_loss: 0.2213 - c_1_loss: 0.9383\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0860 - d_loss_fake: 0.0923 - g_img_loss: 2.8627 - cat_loss: 0.2271 - c_1_loss: 0.8743\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0879 - d_loss_fake: 0.0981 - g_img_loss: 2.6639 - cat_loss: 0.1898 - c_1_loss: 0.9592\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0961 - d_loss_fake: 0.1405 - g_img_loss: 2.4692 - cat_loss: 0.2386 - c_1_loss: 0.9409\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1485 - d_loss_fake: 0.0993 - g_img_loss: 2.7260 - cat_loss: 0.2681 - c_1_loss: 0.9738\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0848 - d_loss_fake: 0.0881 - g_img_loss: 2.7950 - cat_loss: 0.2634 - c_1_loss: 1.0012\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.1682 - d_loss_fake: 0.0947 - g_img_loss: 2.7920 - cat_loss: 0.2102 - c_1_loss: 1.0317\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0656 - d_loss_fake: 0.1040 - g_img_loss: 2.8080 - cat_loss: 0.2185 - c_1_loss: 0.9895\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0999 - d_loss_fake: 0.0895 - g_img_loss: 2.7931 - cat_loss: 0.2553 - c_1_loss: 0.9461\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0718 - d_loss_fake: 0.0774 - g_img_loss: 2.8369 - cat_loss: 0.2110 - c_1_loss: 1.0259\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0583 - d_loss_fake: 0.0805 - g_img_loss: 2.9059 - cat_loss: 0.2462 - c_1_loss: 1.0386\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0553 - d_loss_fake: 0.0721 - g_img_loss: 2.9974 - cat_loss: 0.2102 - c_1_loss: 1.0512\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0620 - d_loss_fake: 0.0643 - g_img_loss: 3.1999 - cat_loss: 0.1547 - c_1_loss: 0.9666\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1472 - d_loss_fake: 0.0571 - g_img_loss: 3.1883 - cat_loss: 0.1509 - c_1_loss: 1.0096\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.1166 - d_loss_fake: 0.0551 - g_img_loss: 3.0899 - cat_loss: 0.1522 - c_1_loss: 0.9626\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0777 - d_loss_fake: 0.0605 - g_img_loss: 3.2330 - cat_loss: 0.1275 - c_1_loss: 1.0512\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0412 - d_loss_fake: 0.0610 - g_img_loss: 3.2932 - cat_loss: 0.1374 - c_1_loss: 0.9776\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0257 - d_loss_fake: 0.0562 - g_img_loss: 3.2476 - cat_loss: 0.1336 - c_1_loss: 0.9442\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0528 - d_loss_fake: 0.0521 - g_img_loss: 3.4535 - cat_loss: 0.1389 - c_1_loss: 0.9553\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0516 - d_loss_fake: 0.0473 - g_img_loss: 3.4358 - cat_loss: 0.1553 - c_1_loss: 0.9566\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0336 - d_loss_fake: 0.0426 - g_img_loss: 3.5068 - cat_loss: 0.1775 - c_1_loss: 1.0002\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0526 - d_loss_fake: 0.0402 - g_img_loss: 3.6732 - cat_loss: 0.0784 - c_1_loss: 0.9440\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0312 - d_loss_fake: 0.0412 - g_img_loss: 3.6739 - cat_loss: 0.0809 - c_1_loss: 0.9256\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0306 - d_loss_fake: 0.0411 - g_img_loss: 3.5997 - cat_loss: 0.0849 - c_1_loss: 0.9397\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0448 - d_loss_fake: 0.0360 - g_img_loss: 3.6397 - cat_loss: 0.1183 - c_1_loss: 0.9636\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0519 - d_loss_fake: 0.0436 - g_img_loss: 3.6738 - cat_loss: 0.0886 - c_1_loss: 0.9772\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0252 - d_loss_fake: 0.0338 - g_img_loss: 3.6370 - cat_loss: 0.1133 - c_1_loss: 0.9344\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0614 - d_loss_fake: 0.0342 - g_img_loss: 3.7129 - cat_loss: 0.0861 - c_1_loss: 0.9684\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0233 - d_loss_fake: 0.0328 - g_img_loss: 3.7089 - cat_loss: 0.0829 - c_1_loss: 0.9605\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0307 - d_loss_fake: 0.0356 - g_img_loss: 3.7733 - cat_loss: 0.0858 - c_1_loss: 0.9453\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0703 - d_loss_fake: 0.0337 - g_img_loss: 3.6820 - cat_loss: 0.1065 - c_1_loss: 0.9230\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0235 - d_loss_fake: 0.0388 - g_img_loss: 3.6808 - cat_loss: 0.1015 - c_1_loss: 0.9419\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0539 - d_loss_fake: 0.0370 - g_img_loss: 3.6155 - cat_loss: 0.1154 - c_1_loss: 0.9538\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0237 - d_loss_fake: 0.0360 - g_img_loss: 3.6698 - cat_loss: 0.0865 - c_1_loss: 0.9108\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0293 - d_loss_fake: 0.0383 - g_img_loss: 3.6066 - cat_loss: 0.1175 - c_1_loss: 0.9972\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0327 - d_loss_fake: 0.0441 - g_img_loss: 3.5319 - cat_loss: 0.1642 - c_1_loss: 0.9530\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0215 - d_loss_fake: 0.0387 - g_img_loss: 3.5805 - cat_loss: 0.1174 - c_1_loss: 0.9762\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0372 - d_loss_fake: 0.0358 - g_img_loss: 3.7065 - cat_loss: 0.1348 - c_1_loss: 0.9954\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0617 - d_loss_fake: 0.0336 - g_img_loss: 3.7894 - cat_loss: 0.1299 - c_1_loss: 1.0106\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0793 - d_loss_fake: 0.0316 - g_img_loss: 3.7189 - cat_loss: 0.1201 - c_1_loss: 1.0087\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0227 - d_loss_fake: 0.0275 - g_img_loss: 3.7764 - cat_loss: 0.1078 - c_1_loss: 0.9415\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0353 - d_loss_fake: 0.0388 - g_img_loss: 3.8510 - cat_loss: 0.1380 - c_1_loss: 0.9571\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0335 - d_loss_fake: 0.0362 - g_img_loss: 3.8557 - cat_loss: 0.0931 - c_1_loss: 0.9489\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0142 - d_loss_fake: 0.0308 - g_img_loss: 3.9288 - cat_loss: 0.0988 - c_1_loss: 0.9286\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0172 - d_loss_fake: 0.0279 - g_img_loss: 3.9886 - cat_loss: 0.0854 - c_1_loss: 0.9522\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0230 - d_loss_fake: 0.0309 - g_img_loss: 3.9258 - cat_loss: 0.1206 - c_1_loss: 0.9650\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0387 - d_loss_fake: 0.0330 - g_img_loss: 3.7847 - cat_loss: 0.0693 - c_1_loss: 0.9451\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0638 - d_loss_fake: 0.0365 - g_img_loss: 3.8077 - cat_loss: 0.1038 - c_1_loss: 0.9558\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0395 - d_loss_fake: 0.0318 - g_img_loss: 3.8455 - cat_loss: 0.1145 - c_1_loss: 0.9661\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0218 - d_loss_fake: 0.0267 - g_img_loss: 3.9258 - cat_loss: 0.1187 - c_1_loss: 0.9531\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0198 - d_loss_fake: 0.0270 - g_img_loss: 3.9481 - cat_loss: 0.0897 - c_1_loss: 0.9193\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0216 - d_loss_fake: 0.0222 - g_img_loss: 3.9493 - cat_loss: 0.0855 - c_1_loss: 0.9920\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0285 - d_loss_fake: 0.0246 - g_img_loss: 4.1090 - cat_loss: 0.0731 - c_1_loss: 0.9488\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0286 - d_loss_fake: 0.0258 - g_img_loss: 4.0398 - cat_loss: 0.0724 - c_1_loss: 0.9158\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0126 - d_loss_fake: 0.0237 - g_img_loss: 4.0937 - cat_loss: 0.0719 - c_1_loss: 0.9123\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0115 - d_loss_fake: 0.0211 - g_img_loss: 4.0575 - cat_loss: 0.0801 - c_1_loss: 0.9693\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0260 - d_loss_fake: 0.0260 - g_img_loss: 4.0275 - cat_loss: 0.0640 - c_1_loss: 0.9068\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0286 - d_loss_fake: 0.0220 - g_img_loss: 4.0601 - cat_loss: 0.0930 - c_1_loss: 0.8832\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0522 - d_loss_fake: 0.0293 - g_img_loss: 3.7782 - cat_loss: 0.1116 - c_1_loss: 0.9445\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0373 - d_loss_fake: 0.0478 - g_img_loss: 3.4309 - cat_loss: 0.1863 - c_1_loss: 0.9469\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0442 - d_loss_fake: 0.0525 - g_img_loss: 3.3935 - cat_loss: 0.1215 - c_1_loss: 0.9766\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0234 - d_loss_fake: 0.0404 - g_img_loss: 3.4911 - cat_loss: 0.1036 - c_1_loss: 0.9315\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0500 - d_loss_fake: 0.0418 - g_img_loss: 3.5477 - cat_loss: 0.1353 - c_1_loss: 0.9803\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0326 - d_loss_fake: 0.0510 - g_img_loss: 3.5063 - cat_loss: 0.1485 - c_1_loss: 0.9859\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0431 - d_loss_fake: 0.0381 - g_img_loss: 3.5859 - cat_loss: 0.2021 - c_1_loss: 0.9677\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0155 - d_loss_fake: 0.0371 - g_img_loss: 3.7216 - cat_loss: 0.1975 - c_1_loss: 0.9405\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0360 - d_loss_fake: 0.0327 - g_img_loss: 3.7968 - cat_loss: 0.1529 - c_1_loss: 1.0425\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0248 - d_loss_fake: 0.0389 - g_img_loss: 3.6551 - cat_loss: 0.1303 - c_1_loss: 0.9561\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0543 - d_loss_fake: 0.0446 - g_img_loss: 3.6396 - cat_loss: 0.1391 - c_1_loss: 0.9481\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0340 - d_loss_fake: 0.0620 - g_img_loss: 3.6345 - cat_loss: 0.1224 - c_1_loss: 0.9484\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0479 - d_loss_fake: 0.0506 - g_img_loss: 3.7682 - cat_loss: 0.1085 - c_1_loss: 1.0120\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0257 - d_loss_fake: 0.0407 - g_img_loss: 3.8603 - cat_loss: 0.1483 - c_1_loss: 0.9490\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0259 - d_loss_fake: 0.0282 - g_img_loss: 3.9092 - cat_loss: 0.0942 - c_1_loss: 0.9382\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0326 - d_loss_fake: 0.0243 - g_img_loss: 4.0113 - cat_loss: 0.1002 - c_1_loss: 0.9318\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0303 - d_loss_fake: 0.0360 - g_img_loss: 3.5043 - cat_loss: 0.1284 - c_1_loss: 0.9687\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0996 - d_loss_fake: 0.0331 - g_img_loss: 3.4543 - cat_loss: 0.1640 - c_1_loss: 0.9623\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0343 - d_loss_fake: 0.0641 - g_img_loss: 3.5619 - cat_loss: 0.2365 - c_1_loss: 0.9505\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0336 - d_loss_fake: 0.0351 - g_img_loss: 3.7683 - cat_loss: 0.2638 - c_1_loss: 0.9747\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0370 - d_loss_fake: 0.0312 - g_img_loss: 3.9470 - cat_loss: 0.2016 - c_1_loss: 0.9954\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0278 - d_loss_fake: 0.0368 - g_img_loss: 3.8327 - cat_loss: 0.2173 - c_1_loss: 0.9494\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0416 - d_loss_fake: 0.0289 - g_img_loss: 3.8631 - cat_loss: 0.2042 - c_1_loss: 1.0111\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0272 - d_loss_fake: 0.0302 - g_img_loss: 3.8681 - cat_loss: 0.1631 - c_1_loss: 0.9548\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0389 - d_loss_fake: 0.0294 - g_img_loss: 3.8813 - cat_loss: 0.1893 - c_1_loss: 0.9951\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0232 - d_loss_fake: 0.0297 - g_img_loss: 4.0354 - cat_loss: 0.1985 - c_1_loss: 0.9778\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0619 - d_loss_fake: 0.0277 - g_img_loss: 4.1238 - cat_loss: 0.1943 - c_1_loss: 0.9593\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0261 - d_loss_fake: 0.0225 - g_img_loss: 4.2692 - cat_loss: 0.1323 - c_1_loss: 0.9348\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0216 - d_loss_fake: 0.0232 - g_img_loss: 4.1713 - cat_loss: 0.1550 - c_1_loss: 0.9381\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0367 - d_loss_fake: 0.0286 - g_img_loss: 4.2642 - cat_loss: 0.1289 - c_1_loss: 0.9369\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0278 - d_loss_fake: 0.0350 - g_img_loss: 4.0204 - cat_loss: 0.2347 - c_1_loss: 0.9184\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0186 - d_loss_fake: 0.0458 - g_img_loss: 3.7520 - cat_loss: 0.2002 - c_1_loss: 0.9785\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0313 - d_loss_fake: 0.0487 - g_img_loss: 3.6226 - cat_loss: 0.2167 - c_1_loss: 1.0533\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0353 - d_loss_fake: 0.0441 - g_img_loss: 3.4464 - cat_loss: 0.1874 - c_1_loss: 1.0161\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0199 - d_loss_fake: 0.0504 - g_img_loss: 3.5109 - cat_loss: 0.1933 - c_1_loss: 0.9581\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0239 - d_loss_fake: 0.0439 - g_img_loss: 3.7792 - cat_loss: 0.0820 - c_1_loss: 0.9591\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0216 - d_loss_fake: 0.0321 - g_img_loss: 3.9304 - cat_loss: 0.0766 - c_1_loss: 0.8965\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0287 - d_loss_fake: 0.0265 - g_img_loss: 4.1156 - cat_loss: 0.0767 - c_1_loss: 0.9125\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0919 - d_loss_fake: 0.0251 - g_img_loss: 4.0218 - cat_loss: 0.0769 - c_1_loss: 0.9660\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0396 - d_loss_fake: 0.0332 - g_img_loss: 3.8474 - cat_loss: 0.0929 - c_1_loss: 0.9352\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0183 - d_loss_fake: 0.0347 - g_img_loss: 3.9642 - cat_loss: 0.0394 - c_1_loss: 0.9063\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0313 - d_loss_fake: 0.0251 - g_img_loss: 4.0289 - cat_loss: 0.1020 - c_1_loss: 0.9318\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0200 - d_loss_fake: 0.0258 - g_img_loss: 4.0025 - cat_loss: 0.1168 - c_1_loss: 0.9331\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0200 - d_loss_fake: 0.0373 - g_img_loss: 3.8519 - cat_loss: 0.1196 - c_1_loss: 0.9196\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0223 - d_loss_fake: 0.0366 - g_img_loss: 3.9412 - cat_loss: 0.0691 - c_1_loss: 0.9072\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0308 - d_loss_fake: 0.0297 - g_img_loss: 4.0437 - cat_loss: 0.0756 - c_1_loss: 0.9440\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0339 - d_loss_fake: 0.0223 - g_img_loss: 4.2290 - cat_loss: 0.0522 - c_1_loss: 0.9448\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0220 - d_loss_fake: 0.0230 - g_img_loss: 4.2456 - cat_loss: 0.0759 - c_1_loss: 0.9024\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0218 - d_loss_fake: 0.0209 - g_img_loss: 4.3328 - cat_loss: 0.0898 - c_1_loss: 0.8863\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0194 - d_loss_fake: 0.0206 - g_img_loss: 4.2972 - cat_loss: 0.0863 - c_1_loss: 0.9683\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0217 - d_loss_fake: 0.0223 - g_img_loss: 4.1724 - cat_loss: 0.0765 - c_1_loss: 0.9349\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0199 - d_loss_fake: 0.0268 - g_img_loss: 4.0664 - cat_loss: 0.0577 - c_1_loss: 0.8877\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0343 - d_loss_fake: 0.0329 - g_img_loss: 4.0188 - cat_loss: 0.1328 - c_1_loss: 0.9251\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0220 - d_loss_fake: 0.0402 - g_img_loss: 3.9318 - cat_loss: 0.1260 - c_1_loss: 0.9516\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0348 - d_loss_fake: 0.0453 - g_img_loss: 3.5497 - cat_loss: 0.1553 - c_1_loss: 0.9682\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0272 - d_loss_fake: 0.0629 - g_img_loss: 3.2628 - cat_loss: 0.2650 - c_1_loss: 0.9368\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0210 - d_loss_fake: 0.0511 - g_img_loss: 3.5534 - cat_loss: 0.2242 - c_1_loss: 0.9152\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0402 - d_loss_fake: 0.0366 - g_img_loss: 3.8911 - cat_loss: 0.1976 - c_1_loss: 0.9310\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0357 - d_loss_fake: 0.0323 - g_img_loss: 4.0899 - cat_loss: 0.1277 - c_1_loss: 0.9824\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0395 - d_loss_fake: 0.0239 - g_img_loss: 4.2224 - cat_loss: 0.1098 - c_1_loss: 1.0130\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0261 - d_loss_fake: 0.0211 - g_img_loss: 4.1148 - cat_loss: 0.1428 - c_1_loss: 0.9612\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0180 - d_loss_fake: 0.0273 - g_img_loss: 4.0000 - cat_loss: 0.1974 - c_1_loss: 0.9696\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0240 - d_loss_fake: 0.0234 - g_img_loss: 3.9929 - cat_loss: 0.1528 - c_1_loss: 0.9857\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0189 - d_loss_fake: 0.0245 - g_img_loss: 3.9854 - cat_loss: 0.0816 - c_1_loss: 0.9234\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0175 - d_loss_fake: 0.0255 - g_img_loss: 3.8776 - cat_loss: 0.1020 - c_1_loss: 0.9933\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0194 - d_loss_fake: 0.0302 - g_img_loss: 3.9240 - cat_loss: 0.1017 - c_1_loss: 0.9635\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0229 - d_loss_fake: 0.0212 - g_img_loss: 4.1693 - cat_loss: 0.0764 - c_1_loss: 0.9712\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0270 - d_loss_fake: 0.0207 - g_img_loss: 4.1465 - cat_loss: 0.1131 - c_1_loss: 0.9478\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0191 - d_loss_fake: 0.0232 - g_img_loss: 4.2379 - cat_loss: 0.1070 - c_1_loss: 0.9947\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0129 - d_loss_fake: 0.0214 - g_img_loss: 4.3326 - cat_loss: 0.1470 - c_1_loss: 0.9300\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0130 - d_loss_fake: 0.0170 - g_img_loss: 4.4290 - cat_loss: 0.0692 - c_1_loss: 0.9819\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0474 - d_loss_fake: 0.0148 - g_img_loss: 4.4247 - cat_loss: 0.0562 - c_1_loss: 0.9355\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0131 - d_loss_fake: 0.0165 - g_img_loss: 4.3741 - cat_loss: 0.0770 - c_1_loss: 0.9641\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0499 - d_loss_fake: 0.0167 - g_img_loss: 4.3218 - cat_loss: 0.0521 - c_1_loss: 0.9455\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0245 - d_loss_fake: 0.0197 - g_img_loss: 4.2119 - cat_loss: 0.0475 - c_1_loss: 0.9328\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0193 - d_loss_fake: 0.0240 - g_img_loss: 4.2113 - cat_loss: 0.0563 - c_1_loss: 0.9015\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0138 - d_loss_fake: 0.0243 - g_img_loss: 4.1238 - cat_loss: 0.0972 - c_1_loss: 0.9291\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0332 - d_loss_fake: 0.0259 - g_img_loss: 3.8905 - cat_loss: 0.1025 - c_1_loss: 0.9255\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0215 - d_loss_fake: 0.0408 - g_img_loss: 3.6067 - cat_loss: 0.1304 - c_1_loss: 0.9469\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 14ms/step - d_loss_real: 0.0396 - d_loss_fake: 0.0403 - g_img_loss: 3.8677 - cat_loss: 0.0925 - c_1_loss: 0.9479\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0205 - d_loss_fake: 0.0337 - g_img_loss: 4.0508 - cat_loss: 0.1082 - c_1_loss: 0.9435\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0521 - d_loss_fake: 0.0290 - g_img_loss: 4.2803 - cat_loss: 0.0489 - c_1_loss: 0.9795\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0398 - d_loss_fake: 0.0230 - g_img_loss: 4.3000 - cat_loss: 0.0465 - c_1_loss: 0.9374\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0165 - d_loss_fake: 0.0299 - g_img_loss: 4.1768 - cat_loss: 0.0723 - c_1_loss: 0.9270\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0227 - d_loss_fake: 0.0238 - g_img_loss: 4.3718 - cat_loss: 0.0893 - c_1_loss: 0.9258\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0128 - d_loss_fake: 0.0170 - g_img_loss: 4.4685 - cat_loss: 0.0865 - c_1_loss: 0.9699\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0177 - d_loss_fake: 0.0172 - g_img_loss: 4.3845 - cat_loss: 0.0985 - c_1_loss: 0.9399\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0216 - d_loss_fake: 0.0215 - g_img_loss: 4.1570 - cat_loss: 0.1396 - c_1_loss: 0.9393\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0236 - d_loss_fake: 0.0246 - g_img_loss: 3.7900 - cat_loss: 0.1186 - c_1_loss: 0.9871\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0313 - d_loss_fake: 0.0373 - g_img_loss: 3.6607 - cat_loss: 0.3191 - c_1_loss: 0.9647\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0145 - d_loss_fake: 0.0289 - g_img_loss: 4.0384 - cat_loss: 0.1260 - c_1_loss: 0.9622\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0205 - d_loss_fake: 0.0249 - g_img_loss: 4.1666 - cat_loss: 0.0933 - c_1_loss: 1.0048\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0185 - d_loss_fake: 0.0204 - g_img_loss: 4.3807 - cat_loss: 0.1065 - c_1_loss: 0.9637\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0211 - d_loss_fake: 0.0166 - g_img_loss: 4.3804 - cat_loss: 0.0714 - c_1_loss: 0.9303\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0224 - d_loss_fake: 0.0139 - g_img_loss: 4.4299 - cat_loss: 0.1035 - c_1_loss: 0.9679\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0355 - d_loss_fake: 0.0143 - g_img_loss: 4.5269 - cat_loss: 0.0512 - c_1_loss: 0.9436\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0185 - d_loss_fake: 0.0142 - g_img_loss: 4.5420 - cat_loss: 0.0476 - c_1_loss: 0.9109\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0258 - d_loss_fake: 0.0132 - g_img_loss: 4.5600 - cat_loss: 0.0427 - c_1_loss: 0.8972\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0184 - d_loss_fake: 0.0140 - g_img_loss: 4.5026 - cat_loss: 0.0574 - c_1_loss: 0.8770\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0122 - d_loss_fake: 0.0117 - g_img_loss: 4.5639 - cat_loss: 0.0698 - c_1_loss: 0.9307\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0256 - d_loss_fake: 0.0123 - g_img_loss: 4.5698 - cat_loss: 0.0196 - c_1_loss: 0.9442\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0255 - d_loss_fake: 0.0141 - g_img_loss: 4.6027 - cat_loss: 0.0452 - c_1_loss: 0.9082\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0147 - d_loss_fake: 0.0135 - g_img_loss: 4.5317 - cat_loss: 0.0782 - c_1_loss: 0.8649\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0128 - d_loss_fake: 0.0159 - g_img_loss: 4.4608 - cat_loss: 0.0221 - c_1_loss: 0.9141\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0118 - d_loss_fake: 0.0141 - g_img_loss: 4.6408 - cat_loss: 0.0340 - c_1_loss: 0.9076\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0099 - d_loss_fake: 0.0121 - g_img_loss: 4.6698 - cat_loss: 0.0362 - c_1_loss: 0.8947\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0108 - d_loss_fake: 0.0112 - g_img_loss: 4.7316 - cat_loss: 0.0642 - c_1_loss: 0.8589\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0093 - d_loss_fake: 0.0108 - g_img_loss: 4.8219 - cat_loss: 0.0264 - c_1_loss: 0.8678\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0086 - d_loss_fake: 0.0130 - g_img_loss: 4.7260 - cat_loss: 0.0976 - c_1_loss: 0.9022\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0086 - d_loss_fake: 0.0173 - g_img_loss: 4.5588 - cat_loss: 0.0992 - c_1_loss: 0.9342\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0118 - d_loss_fake: 0.0177 - g_img_loss: 4.4307 - cat_loss: 0.0662 - c_1_loss: 0.9687\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0091 - d_loss_fake: 0.0171 - g_img_loss: 4.5776 - cat_loss: 0.1346 - c_1_loss: 0.9673\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0093 - d_loss_fake: 0.0178 - g_img_loss: 4.4501 - cat_loss: 0.0279 - c_1_loss: 0.8989\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0141 - d_loss_fake: 0.0122 - g_img_loss: 4.6284 - cat_loss: 0.0345 - c_1_loss: 0.9480\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0115 - d_loss_fake: 0.0119 - g_img_loss: 4.7327 - cat_loss: 0.0650 - c_1_loss: 0.9060\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0193 - d_loss_fake: 0.0121 - g_img_loss: 4.8157 - cat_loss: 0.0738 - c_1_loss: 0.9155\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0086 - d_loss_fake: 0.0121 - g_img_loss: 4.7438 - cat_loss: 0.0927 - c_1_loss: 0.8891\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0103 - d_loss_fake: 0.0134 - g_img_loss: 4.7504 - cat_loss: 0.0763 - c_1_loss: 0.9211\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0252 - d_loss_fake: 0.0128 - g_img_loss: 4.7089 - cat_loss: 0.0361 - c_1_loss: 0.9573\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0156 - d_loss_fake: 0.0135 - g_img_loss: 4.6840 - cat_loss: 0.0736 - c_1_loss: 0.9381\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0070 - d_loss_fake: 0.0118 - g_img_loss: 4.5783 - cat_loss: 0.1478 - c_1_loss: 0.9591\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0094 - d_loss_fake: 0.0104 - g_img_loss: 4.6760 - cat_loss: 0.0394 - c_1_loss: 0.9719\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0104 - d_loss_fake: 0.0110 - g_img_loss: 4.8413 - cat_loss: 0.0332 - c_1_loss: 0.9260\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 20ms/step - d_loss_real: 0.0121 - d_loss_fake: 0.0106 - g_img_loss: 4.6713 - cat_loss: 0.0914 - c_1_loss: 0.8612\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0157 - d_loss_fake: 0.0162 - g_img_loss: 4.5081 - cat_loss: 0.1477 - c_1_loss: 0.9508\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0262 - d_loss_fake: 0.0133 - g_img_loss: 4.5404 - cat_loss: 0.0511 - c_1_loss: 0.9268\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0202 - d_loss_fake: 0.0174 - g_img_loss: 4.3661 - cat_loss: 0.0688 - c_1_loss: 0.9298\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0144 - d_loss_fake: 0.0195 - g_img_loss: 4.5277 - cat_loss: 0.1098 - c_1_loss: 0.9717\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0116 - d_loss_fake: 0.0150 - g_img_loss: 4.5976 - cat_loss: 0.0877 - c_1_loss: 0.9297\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0230 - d_loss_fake: 0.0120 - g_img_loss: 4.6702 - cat_loss: 0.0741 - c_1_loss: 0.9150\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0163 - d_loss_fake: 0.0153 - g_img_loss: 4.4490 - cat_loss: 0.1326 - c_1_loss: 0.9160\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0418 - d_loss_fake: 0.0147 - g_img_loss: 4.4307 - cat_loss: 0.1265 - c_1_loss: 0.9269\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0164 - d_loss_fake: 0.0122 - g_img_loss: 4.5844 - cat_loss: 0.1345 - c_1_loss: 0.9200\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0115 - d_loss_fake: 0.0154 - g_img_loss: 4.6596 - cat_loss: 0.1228 - c_1_loss: 0.9626\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0111 - d_loss_fake: 0.0120 - g_img_loss: 4.6852 - cat_loss: 0.0884 - c_1_loss: 0.9413\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0174 - d_loss_fake: 0.0142 - g_img_loss: 4.6261 - cat_loss: 0.0990 - c_1_loss: 0.9230\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0132 - d_loss_fake: 0.0122 - g_img_loss: 4.7039 - cat_loss: 0.0839 - c_1_loss: 0.9454\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 20ms/step - d_loss_real: 0.0129 - d_loss_fake: 0.0146 - g_img_loss: 4.6538 - cat_loss: 0.0809 - c_1_loss: 0.9833\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0111 - d_loss_fake: 0.0164 - g_img_loss: 4.5537 - cat_loss: 0.0897 - c_1_loss: 0.9040\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0093 - d_loss_fake: 0.0145 - g_img_loss: 4.5641 - cat_loss: 0.1408 - c_1_loss: 1.0243\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0155 - d_loss_fake: 0.0129 - g_img_loss: 4.6452 - cat_loss: 0.0742 - c_1_loss: 0.9258\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0235 - d_loss_fake: 0.0116 - g_img_loss: 4.5765 - cat_loss: 0.0859 - c_1_loss: 0.9387\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0125 - d_loss_fake: 0.0134 - g_img_loss: 4.6784 - cat_loss: 0.1172 - c_1_loss: 0.9034\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0160 - d_loss_fake: 0.0120 - g_img_loss: 4.6852 - cat_loss: 0.0864 - c_1_loss: 0.9126\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0132 - d_loss_fake: 0.0108 - g_img_loss: 4.8661 - cat_loss: 0.0485 - c_1_loss: 0.9363\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0119 - d_loss_fake: 0.0118 - g_img_loss: 4.8589 - cat_loss: 0.0457 - c_1_loss: 0.9292\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0244 - d_loss_fake: 0.0087 - g_img_loss: 4.9288 - cat_loss: 0.0881 - c_1_loss: 0.9195\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0045 - d_loss_fake: 0.0114 - g_img_loss: 4.9542 - cat_loss: 0.0745 - c_1_loss: 0.9376\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0059 - d_loss_fake: 0.0095 - g_img_loss: 4.9404 - cat_loss: 0.0941 - c_1_loss: 0.9489\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0081 - d_loss_fake: 0.0086 - g_img_loss: 4.8423 - cat_loss: 0.0408 - c_1_loss: 0.9220\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0086 - d_loss_fake: 0.0154 - g_img_loss: 4.7060 - cat_loss: 0.0783 - c_1_loss: 0.9411\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0069 - d_loss_fake: 0.0259 - g_img_loss: 4.1903 - cat_loss: 0.2544 - c_1_loss: 0.9443\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0105 - d_loss_fake: 0.0243 - g_img_loss: 4.3345 - cat_loss: 0.1463 - c_1_loss: 0.9186\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0203 - d_loss_fake: 0.0213 - g_img_loss: 4.5844 - cat_loss: 0.1172 - c_1_loss: 0.9690\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0142 - d_loss_fake: 0.0137 - g_img_loss: 4.6966 - cat_loss: 0.0711 - c_1_loss: 0.8997\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0120 - d_loss_fake: 0.0168 - g_img_loss: 4.6889 - cat_loss: 0.0706 - c_1_loss: 0.9610\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0188 - d_loss_fake: 0.0117 - g_img_loss: 4.7264 - cat_loss: 0.0924 - c_1_loss: 0.9417\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0086 - d_loss_fake: 0.0118 - g_img_loss: 4.8259 - cat_loss: 0.0498 - c_1_loss: 0.8858\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0136 - d_loss_fake: 0.0104 - g_img_loss: 5.0194 - cat_loss: 0.0318 - c_1_loss: 0.8829\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0187 - d_loss_fake: 0.0118 - g_img_loss: 4.9934 - cat_loss: 0.0460 - c_1_loss: 0.9036\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 18ms/step - d_loss_real: 0.0113 - d_loss_fake: 0.0160 - g_img_loss: 4.8926 - cat_loss: 0.0799 - c_1_loss: 0.9181\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0092 - d_loss_fake: 0.0133 - g_img_loss: 4.7098 - cat_loss: 0.1376 - c_1_loss: 0.9430\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0136 - d_loss_fake: 0.0147 - g_img_loss: 4.6671 - cat_loss: 0.2525 - c_1_loss: 0.9484\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0074 - d_loss_fake: 0.0100 - g_img_loss: 5.0514 - cat_loss: 0.1288 - c_1_loss: 0.9348\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0104 - d_loss_fake: 0.0083 - g_img_loss: 5.0879 - cat_loss: 0.0649 - c_1_loss: 0.9643\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0268 - d_loss_fake: 0.0094 - g_img_loss: 5.0295 - cat_loss: 0.0352 - c_1_loss: 0.8957\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0138 - d_loss_fake: 0.0089 - g_img_loss: 5.1168 - cat_loss: 0.0680 - c_1_loss: 0.8936\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.1215 - d_loss_fake: 0.0083 - g_img_loss: 5.0577 - cat_loss: 0.0544 - c_1_loss: 0.9417\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 19ms/step - d_loss_real: 0.0154 - d_loss_fake: 0.0213 - g_img_loss: 4.7902 - cat_loss: 0.0674 - c_1_loss: 0.8788\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 15ms/step - d_loss_real: 0.0190 - d_loss_fake: 0.0210 - g_img_loss: 4.6090 - cat_loss: 0.0618 - c_1_loss: 0.9633\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0530 - d_loss_fake: 0.0175 - g_img_loss: 4.5773 - cat_loss: 0.0707 - c_1_loss: 0.9110\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 16ms/step - d_loss_real: 0.0225 - d_loss_fake: 0.0177 - g_img_loss: 4.5938 - cat_loss: 0.0881 - c_1_loss: 0.9298\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0197 - d_loss_fake: 0.0247 - g_img_loss: 4.4618 - cat_loss: 0.0748 - c_1_loss: 0.9020\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 17ms/step - d_loss_real: 0.0089 - d_loss_fake: 0.0244 - g_img_loss: 4.4615 - cat_loss: 0.0777 - c_1_loss: 0.9260\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f30de4a8390>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#take\n",
        "from sklearn.model_selection import train_test_split\n",
        "def load_real_image(batch_size=32):\n",
        "    #(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(np.array(sounds).reshape(len(sounds),40), labels, test_size=0.2, random_state=0)\n",
        "    # Add the color channel - change to 4D tensor, and convert the data type to 'float32'\n",
        "    #train_images = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
        "    train_images = np.array(X_train)\n",
        "    # Set the pixel values from -1 to 1\n",
        "    train_images = (train_images/255.0) * 2 - 1\n",
        "    df = pd.DataFrame(y_train, columns=['Class'])\n",
        "    # creating instance of labelencoder\n",
        "    labelencoder = LabelEncoder()\n",
        "    # Assigning numerical values and storing in another column\n",
        "    df['Class_cat'] = labelencoder.fit_transform(df['Class'])\n",
        "    y = df[['Class_cat']].to_numpy().reshape(len(X_train))\n",
        "    label1 = tf.one_hot(y, depth=6)\n",
        "    print(label1.shape)\n",
        "    c1 = tf.ones(len(X_train), 1)\n",
        "    c1 = c1.numpy().reshape(len(X_train), 1)\n",
        "    gen_input = concat_inputs([label1, c1, train_images])\n",
        "    # Shuffle and separate in batch\n",
        "    print(gen_input.shape)\n",
        "    buffer_size = train_images.shape[0]\n",
        "\n",
        "    #train_images_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)\n",
        "    return gen_input\n",
        "g_model_continuous=create_generator_continuous()\n",
        "d_model_continuous,q_model_continuous=create_discriminator_continuous()\n",
        "infogan = InfoGAN_Continuous(d_model_continuous, g_model_continuous, q_model_continuous, noise_size=40, num_classes=6)\n",
        "infogan.compile(d_optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4),\n",
        "                g_optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
        "                q_optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4))\n",
        "real_images = load_real_image(batch_size=32)\n",
        "infogan.fit(real_images, epochs=500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvfDAvinqBSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b4752fe-fc4a-49de-d859-cea2477b9396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         ... 0.1201743  0.         0.        ]\n",
            " [0.         0.         0.         ... 0.14276014 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.13946953 0.         0.        ]\n",
            " [0.23485887 0.         0.         ... 0.         0.         0.40678263]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "255\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "x = infogan.g_model.predict(real_images)\n",
        "print(x)\n",
        "print(len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWsWzmebj0Vw"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "def get_samples(label):\n",
        "  \n",
        "  data=[]\n",
        "  \n",
        "  for i in range(len(sounds)):\n",
        "    if enc_labels[i] == label:\n",
        "      data.append(sounds[i])\n",
        "  print(len(data))\n",
        "  gen_num = 2000 - len(data)\n",
        "  #data=(data/255.0) * 2 - 1\n",
        "  data = transform_data(data, label, gen_num)\n",
        "  #data = np.array(data).reshape(len(data), 47)\n",
        "  return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3gIuxASpe7I"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "def transform_data(data, className, num):\n",
        "    \n",
        "    q = num//len(data)\n",
        "    r = num%len(data)\n",
        "    temp=[]\n",
        "    for i in range(q):\n",
        "      for j in range(len(data)):\n",
        "        temp.append(data[j])\n",
        "    for i in range(r):\n",
        "      temp.append(data[i])\n",
        "    batch_size = len(temp)\n",
        "    label = np.arange(batch_size)\n",
        "    label.fill(className)\n",
        "    label = tf.one_hot(label, depth=6)\n",
        "    c1 = tf.ones(batch_size, 1)\n",
        "    c1 = c1.numpy().reshape(batch_size, 1)\n",
        "    temp1 = np.array(temp).reshape(len(temp), 40)  \n",
        "    temp1 = (temp1/255.0) * 2 - 1\n",
        "    return concat_inputs([label, c1, temp1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgWBrN7nqFVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70df7d3-1ba3-4b58-89a7-b9a451d96f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "3\n",
            "263\n",
            "13\n",
            "26\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "gen_x=[]\n",
        "gen_y=[]\n",
        "df = pd.DataFrame(labels, columns=['Class'])\n",
        "    # creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "    # Assigning numerical values and storing in another column\n",
        "df['Class_cat'] = labelencoder.fit_transform(df['Class'])\n",
        "enc_labels = df[['Class_cat']].to_numpy().reshape(len(sounds))\n",
        "\n",
        "for i in range(6):\n",
        "  samples = get_samples(i)\n",
        "  y = np.arange(len(samples))\n",
        "  y.fill(i)\n",
        "  if i==0:\n",
        "    gen_x = np.array(samples)\n",
        "    gen_y = np.array(y)\n",
        "  else:\n",
        "    gen_x = np.concatenate((gen_x, samples),axis=0)\n",
        "    gen_y = np.concatenate((np.array(gen_y), np.array(y)), axis=0)\n",
        "gen_x = np.array(gen_x).reshape(len(gen_x),47)\n",
        "gen_y = labelencoder.inverse_transform(gen_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld11fRRUuyd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d86bb5-1bbd-4a8a-d999-cee6ee65eccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.          0.          0.         ... -0.80080944 -0.8300862\n",
            "  -1.        ]\n",
            " [ 1.          0.          0.         ... -0.80813736 -0.81651944\n",
            "  -1.        ]\n",
            " [ 1.          0.          0.         ... -0.8183458  -0.84656763\n",
            "  -1.        ]\n",
            " ...\n",
            " [ 0.          0.          0.         ... -0.8017075  -0.8287334\n",
            "  -1.        ]\n",
            " [ 0.          0.          0.         ... -0.76861525 -0.77409464\n",
            "  -1.        ]\n",
            " [ 0.          0.          0.         ... -0.79243153 -0.81853276\n",
            "  -1.        ]]\n",
            "['Bronchiectasis' 'Bronchiectasis' 'Bronchiectasis' ... 'URTI' 'URTI'\n",
            " 'URTI']\n",
            "URTI\n",
            "['Bronchiectasis' 'Bronchiolitis' 'COPD' 'Healthy' 'Pneumonia' 'URTI']\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "print(gen_x)\n",
        "print(gen_y)\n",
        "gen_y1 = np.sort(gen_y)\n",
        "print(gen_y1[11000])\n",
        "print(labelencoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5dZEi7YwlgY"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "gen_x=infogan.g_model.predict(gen_x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnDj_K2-22u3",
        "outputId": "75f56465-cf31-4e0c-af4c-6515f7e41ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11681\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "print(len(gen_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8kCTM_K3er-",
        "outputId": "d4774489-6247-4b1a-ff57-fa11082f235f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12000, 40)\n",
            "(12000, 1)\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "new_gen_x = np.delete(np.array(gen_x).reshape(len(gen_x), 47), [0,1,2,3,4,5,6], axis=1)\n",
        "new_x = np.concatenate((np.array(sounds).reshape(len(sounds), 40), new_gen_x), axis=0)\n",
        "print(new_x.shape)\n",
        "new_y = np.concatenate((np.array(labels).reshape(len(labels),1), np.array(gen_y).reshape(len(gen_y),1)), axis=0)\n",
        "print(new_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('gan_sounds',np.array(new_x))\n",
        "np.save('gan_labels',np.array(new_y))"
      ],
      "metadata": {
        "id": "r83tJQNFuTVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_x = np.load(\"gan_sounds.npy\")\n",
        "print(np.array(new_x).shape)\n",
        "new_y = np.load(\"gan_labels.npy\", allow_pickle=True)\n",
        "print(np.array(new_y).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1WQauz62lrX",
        "outputId": "7044ab0c-64cb-41f6-f7db-c9b558f83c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12000, 40)\n",
            "(12000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Implementation of Deep neural Network"
      ],
      "metadata": {
        "id": "Zvq-YgL8bnYy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4kCc5UZmg0b"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import add, Conv2D,Input,BatchNormalization,TimeDistributed,Embedding,LSTM,GRU,Dense,MaxPooling1D,Dropout,LeakyReLU,ReLU,Flatten,concatenate,Bidirectional\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.models import Model,load_model\n",
        "\n",
        "def InstantiateModel(in_):\n",
        "   model_2_1 = GRU(32,return_sequences=True,activation=None,go_backwards=True)(in_)\n",
        "   model_2 = LeakyReLU()(model_2_1)\n",
        "   model_2 = GRU(128,return_sequences=True, activation=None,go_backwards=True)(model_2)\n",
        "   #model_2 = BatchNormalization()(model_2)\n",
        "   model_2 = LeakyReLU()(model_2)\n",
        "    \n",
        "   model_3 = GRU(64,return_sequences=True,activation=None,go_backwards=True)(in_)\n",
        "   model_3 = LeakyReLU()(model_3)\n",
        "   model_3 = GRU(128,return_sequences=True, activation=None,go_backwards=True)(model_3)\n",
        "    #model_3 = BatchNormalization()(model_3)\n",
        "   model_3 = LeakyReLU()(model_3)\n",
        "    \n",
        "   model_add_1 = add([model_3,model_2])\n",
        "    \n",
        "   model_5 = GRU(128,return_sequences=True,activation=None,go_backwards=True)(model_add_1)\n",
        "   model_5 = LeakyReLU()(model_5)\n",
        "   model_5 = GRU(32,return_sequences=True, activation=None,go_backwards=True)(model_5)\n",
        "   model_5 = LeakyReLU()(model_5)\n",
        "    \n",
        "   model_6 = GRU(64,return_sequences=True,activation=None,go_backwards=True)(model_add_1)\n",
        "   model_6 = LeakyReLU()(model_6)\n",
        "   model_6 = GRU(32,return_sequences=True, activation=None,go_backwards=True)(model_6)\n",
        "   model_6 = LeakyReLU()(model_6)\n",
        "    \n",
        "   model_add_2 = add([model_5,model_6,model_2_1])\n",
        "    \n",
        "    \n",
        "   model_7 = Dense(64, activation=None)(model_add_2)\n",
        "   model_7 = LeakyReLU()(model_7)\n",
        "   model_7 = Dropout(0.2)(model_7)\n",
        "   model_7 = Dense(16, activation=None)(model_7)\n",
        "   model_7 = LeakyReLU()(model_7)\n",
        "    \n",
        "   model_9 = Dense(32, activation=None)(model_add_2)\n",
        "   model_9 = LeakyReLU()(model_9)\n",
        "   model_9 = Dropout(0.2)(model_9)\n",
        "   model_9 = Dense(16, activation=None)(model_9)\n",
        "   model_9 = LeakyReLU()(model_9)\n",
        "    \n",
        "   model_add_3 = add([model_7,model_9])\n",
        "   model_add_3 = tf.keras.layers.Flatten()(model_add_3)\n",
        "   model_10 = Dense(16, activation=None)(model_add_3)\n",
        "    #model_10 = BatchNormalization()(model_10)\n",
        "   model_10 = LeakyReLU()(model_10)\n",
        "   model_10 = Dropout(0.5)(model_10)\n",
        "    #Model_7 = MaxPooling1D(pool_size=2)(mode)\n",
        "   model_10 = Dense(6, activation=\"softmax\")(model_10)\n",
        "    \n",
        "   return model_10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXuy2XMXnF-I"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "from keras import backend as K\n",
        "#from models import InstantiateModel\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from keras.layers import Input\n",
        "y_pred=[]\n",
        "DNN_model = []\n",
        "def trainModel(X, y):\n",
        "  K.clear_session()\n",
        "  batch_size=X.shape[0]\n",
        "  time_steps=X.shape[1]\n",
        "  data_dim=X.shape[2]\n",
        "  Input_Sample = Input((time_steps,data_dim))\n",
        "  Output_ = InstantiateModel(Input_Sample)\n",
        "  Model_Enhancer = Model(inputs=Input_Sample, outputs=Output_)\n",
        "  Model_Enhancer.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adamax())\n",
        "  DNN_model=Model_Enhancer\n",
        "  ES = EarlyStopping(monitor='val_loss', min_delta=0.5, patience=200, verbose=1, mode='auto', baseline=None,\n",
        "                              restore_best_weights=False)\n",
        "  MC = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='auto', verbose=0, save_best_only=True)\n",
        "    \n",
        "    #class_weights = class_weight.compute_sample_weight('balanced',\n",
        "\t#                                                 np.unique(y[:,0],axis=0),\n",
        "\t#                                                 y[:,0])\n",
        "  #print(np.unique(y))\n",
        "  X_train, X_test, y_train, y_test = train_test_split(np.array(X).reshape(len(X),40), np.array(y), test_size=0.54, random_state=500)\n",
        "  #print(np.unique(np.array(y_test)))\n",
        "  #print(np.unique(np.array(y_train)))\n",
        "  from tensorflow.keras.utils import to_categorical\n",
        "  \n",
        "  y_binary_train = to_categorical(y_train)\n",
        "  y_binary_test = to_categorical(y_test)\n",
        "  #print(y_binary_train.shape)\n",
        "  print(y_binary_test.shape)\n",
        "  ModelHistory = Model_Enhancer.fit(np.array(X_train).reshape(len(X_train),40,1), y_binary_train,batch_size=batch_size, epochs=200,\n",
        "                                  validation_data=(np.array(X_test).reshape(len(X_test),40,1), y_binary_test),\n",
        "                                  callbacks = [MC],\n",
        "                                  verbose=1)\n",
        "  y_pred = Model_Enhancer.predict(np.array(X_test).reshape(len(X_test), 40, 1), batch_size = batch_size, verbose = 1, callbacks = [MC])\n",
        "  return y_pred, y_test, Model_Enhancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVbIZFEkvfvK"
      },
      "outputs": [],
      "source": [
        "#take\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef\n",
        "from sklearn.metrics import cohen_kappa_score,roc_auc_score,confusion_matrix,classification_report\n",
        "\n",
        "def evalModel(y_test, y_pred):\n",
        "\t'''\n",
        "\t    Evaluate the performance of the model.\n",
        "\t    Args:\n",
        "\t       y_test: The array of features to be tested against.\n",
        "\t       y_pred: Model predictions.\n",
        "        Returns: Accuracy, Precision, Recall, F1 score, Cohens kappa, Matthews correlation coefficient\n",
        "                 of the model after evaluation.\n",
        "\t'''\n",
        "\t  #y_test = y_test.reshape(y_test.shape[0],y_test.shape[2])\n",
        "    #y_test =np.argmax(y_test,axis=1)\n",
        "\n",
        "    # accuracy: (tp + tn) / (p + n)\n",
        "\taccuracy = accuracy_score(y_test, y_pred)\n",
        "\tprint('Accuracy: %f' % accuracy)\n",
        "\t# precision tp / (tp + fp)\n",
        "\tprecision = precision_score(y_test, y_pred,average='weighted')\n",
        "\tprint('Precision: %f' % precision)\n",
        "\t# recall: tp / (tp + fn)\n",
        "\trecall = recall_score(y_test, y_pred,average='weighted')\n",
        "\tprint('Recall: %f' % recall)\n",
        "\t# f1: 2 tp / (2 tp + fp + fn)\n",
        "\tf1 = f1_score(y_test, y_pred,average='weighted')\n",
        "\tprint('F1 score: %f' % f1)\n",
        "\t \n",
        "\t# kappa\n",
        "\tkappa = cohen_kappa_score(y_test, y_pred)\n",
        "\tprint('Cohens kappa: %f' % kappa)\n",
        "\tMatthewsCorrCoef = matthews_corrcoef(y_test, y_pred)\n",
        "\tprint('Matthews correlation coefficient: %f' % MatthewsCorrCoef)\n",
        "\t# ROC AUC\n",
        "\t'''auc = roc_auc_score(y_test, y_pred)\n",
        "\tprint('ROC AUC: %f' % auc)'''\n",
        "\t# confusion matrix\n",
        "\tmatrix = classification_report(y_test, y_pred)\n",
        "\tprint(matrix)\n",
        "\n",
        "\treturn {\n",
        "\t       \"Accuracy\": accuracy,\n",
        "\t       \"Precision\": precision,\n",
        "\t       \"Recall\": recall,\n",
        "\t       \"F1 score\": f1,\n",
        "\t       \"Cohens kappa\": kappa,\n",
        "\t       \"Matthews correlation coefficient\": MatthewsCorrCoef\n",
        "\t}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_cdnQ-7oBGF",
        "outputId": "a790fc24-8b78-428b-ddb3-67461fa4af6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(173, 6)\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 75.8146 - accuracy: 0.0548WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 13s 13s/step - loss: 75.8146 - accuracy: 0.0548 - val_loss: 27.5362 - val_accuracy: 0.0578\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 46.0291 - accuracy: 0.0890WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 46.0291 - accuracy: 0.0890 - val_loss: 6.1453 - val_accuracy: 0.1272\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 18.1411 - accuracy: 0.3699WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 18.1411 - accuracy: 0.3699 - val_loss: 6.8295 - val_accuracy: 0.7977\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.0542 - accuracy: 0.6986WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 8.0542 - accuracy: 0.6986 - val_loss: 9.4678 - val_accuracy: 0.7977\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 9.7078 - accuracy: 0.7192WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 9.7078 - accuracy: 0.7192 - val_loss: 10.6011 - val_accuracy: 0.7977\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.8755 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 7.8755 - accuracy: 0.8151 - val_loss: 10.5018 - val_accuracy: 0.7977\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 8.9950 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 8.9950 - accuracy: 0.7945 - val_loss: 9.7356 - val_accuracy: 0.7977\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 7.7383 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 7.7383 - accuracy: 0.8219 - val_loss: 8.7401 - val_accuracy: 0.7977\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 6.6984 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 6.6984 - accuracy: 0.8014 - val_loss: 7.8410 - val_accuracy: 0.7977\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 5.0760 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 5.0760 - accuracy: 0.7740 - val_loss: 7.0511 - val_accuracy: 0.7977\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.9884 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 4.9884 - accuracy: 0.8014 - val_loss: 6.3783 - val_accuracy: 0.7977\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.7182 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 4.7182 - accuracy: 0.8151 - val_loss: 5.6973 - val_accuracy: 0.7977\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.6911 - accuracy: 0.7260WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 4.6911 - accuracy: 0.7260 - val_loss: 5.1418 - val_accuracy: 0.7977\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.9222 - accuracy: 0.7329WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 4.9222 - accuracy: 0.7329 - val_loss: 4.7202 - val_accuracy: 0.7977\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7039 - accuracy: 0.7603WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 3.7039 - accuracy: 0.7603 - val_loss: 4.3662 - val_accuracy: 0.7977\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9753 - accuracy: 0.7397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 2.9753 - accuracy: 0.7397 - val_loss: 4.0784 - val_accuracy: 0.7977\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.9535 - accuracy: 0.6781WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 4.9535 - accuracy: 0.6781 - val_loss: 3.9160 - val_accuracy: 0.7977\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 4.0542 - accuracy: 0.7260WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 4.0542 - accuracy: 0.7260 - val_loss: 3.7970 - val_accuracy: 0.7977\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.3788 - accuracy: 0.7123WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 3.3788 - accuracy: 0.7123 - val_loss: 3.6989 - val_accuracy: 0.7977\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7504 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 2.7504 - accuracy: 0.7534 - val_loss: 3.6140 - val_accuracy: 0.7977\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0611 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 3.0611 - accuracy: 0.7740 - val_loss: 3.5307 - val_accuracy: 0.7977\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0451 - accuracy: 0.7397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 3.0451 - accuracy: 0.7397 - val_loss: 3.4719 - val_accuracy: 0.7977\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0554 - accuracy: 0.7466WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 3.0554 - accuracy: 0.7466 - val_loss: 3.4350 - val_accuracy: 0.7977\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3737 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 2.3737 - accuracy: 0.7671 - val_loss: 3.3692 - val_accuracy: 0.7977\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.1086 - accuracy: 0.7397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 3.1086 - accuracy: 0.7397 - val_loss: 3.2994 - val_accuracy: 0.7977\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7035 - accuracy: 0.7192WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 2.7035 - accuracy: 0.7192 - val_loss: 3.2846 - val_accuracy: 0.7977\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7594 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 2.7594 - accuracy: 0.7671 - val_loss: 3.2451 - val_accuracy: 0.7977\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.7369 - accuracy: 0.7260WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 3.7369 - accuracy: 0.7260 - val_loss: 3.1731 - val_accuracy: 0.7977\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6340 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 2.6340 - accuracy: 0.7534 - val_loss: 3.1215 - val_accuracy: 0.7977\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.6779 - accuracy: 0.6712WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 3.6779 - accuracy: 0.6712 - val_loss: 3.0918 - val_accuracy: 0.7977\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0242 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 3.0242 - accuracy: 0.7534 - val_loss: 3.0392 - val_accuracy: 0.7977\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.7662 - accuracy: 0.7397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 2.7662 - accuracy: 0.7397 - val_loss: 2.9642 - val_accuracy: 0.7977\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0182 - accuracy: 0.7397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 3.0182 - accuracy: 0.7397 - val_loss: 2.8938 - val_accuracy: 0.7977\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8283 - accuracy: 0.7055WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 2.8283 - accuracy: 0.7055 - val_loss: 2.8717 - val_accuracy: 0.7977\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2439 - accuracy: 0.7397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 2.2439 - accuracy: 0.7397 - val_loss: 2.8481 - val_accuracy: 0.7977\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9006 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 1.9006 - accuracy: 0.7740 - val_loss: 2.8128 - val_accuracy: 0.7977\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 3.0415 - accuracy: 0.7055WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 3.0415 - accuracy: 0.7055 - val_loss: 2.7649 - val_accuracy: 0.7977\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2580 - accuracy: 0.7466WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 2.2580 - accuracy: 0.7466 - val_loss: 2.7205 - val_accuracy: 0.7977\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4302 - accuracy: 0.7466WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 2.4302 - accuracy: 0.7466 - val_loss: 2.6672 - val_accuracy: 0.7977\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1880 - accuracy: 0.7260WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 2.1880 - accuracy: 0.7260 - val_loss: 2.6158 - val_accuracy: 0.7977\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4886 - accuracy: 0.7123WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 2.4886 - accuracy: 0.7123 - val_loss: 2.5959 - val_accuracy: 0.7977\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2525 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 2.2525 - accuracy: 0.7534 - val_loss: 2.5512 - val_accuracy: 0.7977\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.8479 - accuracy: 0.6849WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 2.8479 - accuracy: 0.6849 - val_loss: 2.5264 - val_accuracy: 0.7977\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8537 - accuracy: 0.7466WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 1.8537 - accuracy: 0.7466 - val_loss: 2.5067 - val_accuracy: 0.7977\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4131 - accuracy: 0.7055WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 2.4131 - accuracy: 0.7055 - val_loss: 2.4892 - val_accuracy: 0.7977\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3786 - accuracy: 0.6986WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 2.3786 - accuracy: 0.6986 - val_loss: 2.5023 - val_accuracy: 0.7977\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4536 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 2.4536 - accuracy: 0.7534 - val_loss: 2.5057 - val_accuracy: 0.7977\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9537 - accuracy: 0.6986WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 2.9537 - accuracy: 0.6986 - val_loss: 2.5220 - val_accuracy: 0.7977\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.5339 - accuracy: 0.6849WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 2.5339 - accuracy: 0.6849 - val_loss: 2.5322 - val_accuracy: 0.7977\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6389 - accuracy: 0.7397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 2.6389 - accuracy: 0.7397 - val_loss: 2.5536 - val_accuracy: 0.7977\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9727 - accuracy: 0.7192WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 1.9727 - accuracy: 0.7192 - val_loss: 2.5789 - val_accuracy: 0.7977\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6110 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 1.6110 - accuracy: 0.7534 - val_loss: 2.5949 - val_accuracy: 0.7977\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.9204 - accuracy: 0.7397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 2.9204 - accuracy: 0.7397 - val_loss: 2.6196 - val_accuracy: 0.7977\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9262 - accuracy: 0.7466WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 1.9262 - accuracy: 0.7466 - val_loss: 2.6457 - val_accuracy: 0.7977\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.4590 - accuracy: 0.7466WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 2.4590 - accuracy: 0.7466 - val_loss: 2.6525 - val_accuracy: 0.7977\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2725 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 2.2725 - accuracy: 0.7808 - val_loss: 2.6509 - val_accuracy: 0.7977\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9604 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 1.9604 - accuracy: 0.7534 - val_loss: 2.6361 - val_accuracy: 0.7977\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0971 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 2.0971 - accuracy: 0.8082 - val_loss: 2.6207 - val_accuracy: 0.7977\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3831 - accuracy: 0.7055WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 2.3831 - accuracy: 0.7055 - val_loss: 2.6358 - val_accuracy: 0.7977\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9077 - accuracy: 0.7603WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 1.9077 - accuracy: 0.7603 - val_loss: 2.6478 - val_accuracy: 0.7977\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8995 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 1.8995 - accuracy: 0.7671 - val_loss: 2.6680 - val_accuracy: 0.7977\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8253 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 1.8253 - accuracy: 0.7808 - val_loss: 2.6756 - val_accuracy: 0.7977\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9973 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 1.9973 - accuracy: 0.8014 - val_loss: 2.6640 - val_accuracy: 0.7977\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8045 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 1.8045 - accuracy: 0.8014 - val_loss: 2.6076 - val_accuracy: 0.7977\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8291 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 1.8291 - accuracy: 0.7671 - val_loss: 2.5875 - val_accuracy: 0.7977\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6660 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 1.6660 - accuracy: 0.7740 - val_loss: 2.5671 - val_accuracy: 0.7977\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9842 - accuracy: 0.7466WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 1.9842 - accuracy: 0.7466 - val_loss: 2.5391 - val_accuracy: 0.7977\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7804 - accuracy: 0.7192WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 1.7804 - accuracy: 0.7192 - val_loss: 2.5325 - val_accuracy: 0.7977\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5195 - accuracy: 0.7877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 1.5195 - accuracy: 0.7877 - val_loss: 2.5282 - val_accuracy: 0.7977\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5553 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 1.5553 - accuracy: 0.7808 - val_loss: 2.5101 - val_accuracy: 0.7977\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9401 - accuracy: 0.6918WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 1.9401 - accuracy: 0.6918 - val_loss: 2.5007 - val_accuracy: 0.7977\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8961 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 1.8961 - accuracy: 0.7808 - val_loss: 2.5104 - val_accuracy: 0.7977\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4173 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 1.4173 - accuracy: 0.8151 - val_loss: 2.5436 - val_accuracy: 0.7977\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8511 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 1.8511 - accuracy: 0.7808 - val_loss: 2.5338 - val_accuracy: 0.7977\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0999 - accuracy: 0.7260WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 2.0999 - accuracy: 0.7260 - val_loss: 2.5898 - val_accuracy: 0.7977\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7545 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 1.7545 - accuracy: 0.7671 - val_loss: 2.6576 - val_accuracy: 0.7977\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7709 - accuracy: 0.7466WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 1.7709 - accuracy: 0.7466 - val_loss: 2.7284 - val_accuracy: 0.7977\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7198 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 1.7198 - accuracy: 0.7808 - val_loss: 2.7181 - val_accuracy: 0.7977\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9634 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 1.9634 - accuracy: 0.7808 - val_loss: 2.6507 - val_accuracy: 0.7977\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1017 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 2.1017 - accuracy: 0.8082 - val_loss: 2.5635 - val_accuracy: 0.7977\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5095 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 1.5095 - accuracy: 0.7808 - val_loss: 2.4503 - val_accuracy: 0.7977\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7871 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 1.7871 - accuracy: 0.7740 - val_loss: 2.3635 - val_accuracy: 0.7977\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6802 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 1.6802 - accuracy: 0.7671 - val_loss: 2.2907 - val_accuracy: 0.7977\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5939 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 1.5939 - accuracy: 0.7671 - val_loss: 2.2617 - val_accuracy: 0.7977\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5965 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 1.5965 - accuracy: 0.7740 - val_loss: 2.2107 - val_accuracy: 0.7977\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7679 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 1.7679 - accuracy: 0.7740 - val_loss: 2.2198 - val_accuracy: 0.7977\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0246 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 1.0246 - accuracy: 0.8014 - val_loss: 2.2770 - val_accuracy: 0.7977\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2964 - accuracy: 0.8356WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 1.2964 - accuracy: 0.8356 - val_loss: 2.3678 - val_accuracy: 0.7977\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5063 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 1.5063 - accuracy: 0.7945 - val_loss: 2.4315 - val_accuracy: 0.7977\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3132 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 1.3132 - accuracy: 0.8151 - val_loss: 2.4920 - val_accuracy: 0.7977\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1224 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 1.1224 - accuracy: 0.8082 - val_loss: 2.5809 - val_accuracy: 0.7977\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1567 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 2.1567 - accuracy: 0.7945 - val_loss: 2.5723 - val_accuracy: 0.7977\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8945 - accuracy: 0.7603WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 1.8945 - accuracy: 0.7603 - val_loss: 2.5467 - val_accuracy: 0.7977\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3743 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 2.3743 - accuracy: 0.7534 - val_loss: 2.4835 - val_accuracy: 0.7977\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4492 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 1.4492 - accuracy: 0.8219 - val_loss: 2.3768 - val_accuracy: 0.7977\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5357 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 1.5357 - accuracy: 0.7808 - val_loss: 2.2826 - val_accuracy: 0.7977\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8422 - accuracy: 0.6781WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 1.8422 - accuracy: 0.6781 - val_loss: 2.3650 - val_accuracy: 0.7977\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7221 - accuracy: 0.7329WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 1.7221 - accuracy: 0.7329 - val_loss: 2.4222 - val_accuracy: 0.7977\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1583 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 1.1583 - accuracy: 0.8151 - val_loss: 2.4737 - val_accuracy: 0.7977\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5505 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 1.5505 - accuracy: 0.7534 - val_loss: 2.5719 - val_accuracy: 0.7977\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3091 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 2.3091 - accuracy: 0.7534 - val_loss: 2.5807 - val_accuracy: 0.7977\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6952 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 1.6952 - accuracy: 0.8014 - val_loss: 2.5116 - val_accuracy: 0.7977\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6857 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 1.6857 - accuracy: 0.7808 - val_loss: 2.4282 - val_accuracy: 0.7919\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7884 - accuracy: 0.7534WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 1.7884 - accuracy: 0.7534 - val_loss: 2.4001 - val_accuracy: 0.7977\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5349 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 1.5349 - accuracy: 0.8082 - val_loss: 2.4043 - val_accuracy: 0.7977\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1320 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 2.1320 - accuracy: 0.7671 - val_loss: 2.4400 - val_accuracy: 0.7977\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4989 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4989 - accuracy: 0.7808 - val_loss: 2.5256 - val_accuracy: 0.7977\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7370 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 1.7370 - accuracy: 0.7945 - val_loss: 2.5799 - val_accuracy: 0.7977\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6605 - accuracy: 0.7603WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 1.6605 - accuracy: 0.7603 - val_loss: 2.6166 - val_accuracy: 0.7977\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3559 - accuracy: 0.7877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 1.3559 - accuracy: 0.7877 - val_loss: 2.6311 - val_accuracy: 0.7977\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2048 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 1.2048 - accuracy: 0.8014 - val_loss: 2.6330 - val_accuracy: 0.7977\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4840 - accuracy: 0.8356WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 1.4840 - accuracy: 0.8356 - val_loss: 2.5515 - val_accuracy: 0.7977\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5124 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 1.5124 - accuracy: 0.7808 - val_loss: 2.4279 - val_accuracy: 0.7977\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3275 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 1.3275 - accuracy: 0.7945 - val_loss: 2.4010 - val_accuracy: 0.7977\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6290 - accuracy: 0.7877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 1.6290 - accuracy: 0.7877 - val_loss: 2.3913 - val_accuracy: 0.7977\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9574 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 1.9574 - accuracy: 0.7671 - val_loss: 2.3865 - val_accuracy: 0.7977\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2002 - accuracy: 0.8493WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 1.2002 - accuracy: 0.8493 - val_loss: 2.3336 - val_accuracy: 0.7861\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6877 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 1.6877 - accuracy: 0.8219 - val_loss: 2.3286 - val_accuracy: 0.7919\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4493 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 1.4493 - accuracy: 0.8151 - val_loss: 2.2891 - val_accuracy: 0.7919\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6383 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 1.6383 - accuracy: 0.7945 - val_loss: 2.2750 - val_accuracy: 0.7977\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4975 - accuracy: 0.7877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 1.4975 - accuracy: 0.7877 - val_loss: 2.2026 - val_accuracy: 0.7977\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2942 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 1.2942 - accuracy: 0.8082 - val_loss: 2.1476 - val_accuracy: 0.7919\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2949 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 1.2949 - accuracy: 0.7740 - val_loss: 2.1279 - val_accuracy: 0.7919\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1160 - accuracy: 0.8425WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 1.1160 - accuracy: 0.8425 - val_loss: 2.1440 - val_accuracy: 0.7919\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1916 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 1.1916 - accuracy: 0.8082 - val_loss: 2.1876 - val_accuracy: 0.7919\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2079 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 1.2079 - accuracy: 0.7808 - val_loss: 2.2196 - val_accuracy: 0.7861\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9750 - accuracy: 0.7877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.9750 - accuracy: 0.7877 - val_loss: 2.3011 - val_accuracy: 0.7919\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2921 - accuracy: 0.8356WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 1.2921 - accuracy: 0.8356 - val_loss: 2.4129 - val_accuracy: 0.7977\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1370 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 1.1370 - accuracy: 0.7671 - val_loss: 2.5897 - val_accuracy: 0.7977\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4602 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 1.4602 - accuracy: 0.7945 - val_loss: 2.5913 - val_accuracy: 0.7977\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6548 - accuracy: 0.7877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 1.6548 - accuracy: 0.7877 - val_loss: 2.5958 - val_accuracy: 0.7977\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2555 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 1.2555 - accuracy: 0.7945 - val_loss: 2.5657 - val_accuracy: 0.7977\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2635 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 1.2635 - accuracy: 0.8014 - val_loss: 2.5147 - val_accuracy: 0.7977\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9532 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.9532 - accuracy: 0.8014 - val_loss: 2.4640 - val_accuracy: 0.7977\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5031 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 1.5031 - accuracy: 0.7808 - val_loss: 2.4402 - val_accuracy: 0.7977\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1080 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 1.1080 - accuracy: 0.8082 - val_loss: 2.4459 - val_accuracy: 0.7977\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0275 - accuracy: 0.7260WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 2.0275 - accuracy: 0.7260 - val_loss: 2.5967 - val_accuracy: 0.8035\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1338 - accuracy: 0.7877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 1.1338 - accuracy: 0.7877 - val_loss: 2.6827 - val_accuracy: 0.8035\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5333 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 1.5333 - accuracy: 0.8219 - val_loss: 2.7414 - val_accuracy: 0.8035\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2431 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 1.2431 - accuracy: 0.8082 - val_loss: 2.6317 - val_accuracy: 0.7919\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2677 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 1.2677 - accuracy: 0.7945 - val_loss: 2.5433 - val_accuracy: 0.7861\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2901 - accuracy: 0.7877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 1.2901 - accuracy: 0.7877 - val_loss: 2.4361 - val_accuracy: 0.7861\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8505 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.8505 - accuracy: 0.8082 - val_loss: 2.3484 - val_accuracy: 0.7977\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2562 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 1.2562 - accuracy: 0.7945 - val_loss: 2.3507 - val_accuracy: 0.7919\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8848 - accuracy: 0.8288WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.8848 - accuracy: 0.8288 - val_loss: 2.3869 - val_accuracy: 0.7977\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7761 - accuracy: 0.8356WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.7761 - accuracy: 0.8356 - val_loss: 2.4868 - val_accuracy: 0.7977\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9056 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.9056 - accuracy: 0.7945 - val_loss: 2.5665 - val_accuracy: 0.7977\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8498 - accuracy: 0.8767WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.8498 - accuracy: 0.8767 - val_loss: 2.6259 - val_accuracy: 0.7977\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2775 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 1.2775 - accuracy: 0.8151 - val_loss: 2.6292 - val_accuracy: 0.7977\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0466 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 1.0466 - accuracy: 0.8219 - val_loss: 2.6276 - val_accuracy: 0.7803\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2740 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 1.2740 - accuracy: 0.8151 - val_loss: 2.6246 - val_accuracy: 0.7457\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2952 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 1.2952 - accuracy: 0.8151 - val_loss: 2.6748 - val_accuracy: 0.7457\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1529 - accuracy: 0.7740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 1.1529 - accuracy: 0.7740 - val_loss: 2.7118 - val_accuracy: 0.7457\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4253 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 1.4253 - accuracy: 0.8014 - val_loss: 2.7203 - val_accuracy: 0.7746\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2314 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 1.2314 - accuracy: 0.8151 - val_loss: 2.7351 - val_accuracy: 0.7919\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9936 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.9936 - accuracy: 0.8219 - val_loss: 2.6263 - val_accuracy: 0.7919\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3011 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 1.3011 - accuracy: 0.8014 - val_loss: 2.5518 - val_accuracy: 0.7919\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9186 - accuracy: 0.8356WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.9186 - accuracy: 0.8356 - val_loss: 2.4751 - val_accuracy: 0.7861\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9304 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.9304 - accuracy: 0.8219 - val_loss: 2.4116 - val_accuracy: 0.7688\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7957 - accuracy: 0.8425WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.7957 - accuracy: 0.8425 - val_loss: 2.3604 - val_accuracy: 0.7746\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6018 - accuracy: 0.8425WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.6018 - accuracy: 0.8425 - val_loss: 2.4182 - val_accuracy: 0.7630\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1566 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 1.1566 - accuracy: 0.8219 - val_loss: 2.4661 - val_accuracy: 0.7688\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1320 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 1.1320 - accuracy: 0.8082 - val_loss: 2.5265 - val_accuracy: 0.8035\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7985 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.7985 - accuracy: 0.8219 - val_loss: 2.5679 - val_accuracy: 0.8035\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0907 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 766ms/step - loss: 1.0907 - accuracy: 0.8151 - val_loss: 2.5893 - val_accuracy: 0.8092\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0537 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 1.0537 - accuracy: 0.8014 - val_loss: 2.6010 - val_accuracy: 0.7977\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1583 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 1.1583 - accuracy: 0.8219 - val_loss: 2.6208 - val_accuracy: 0.8092\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9077 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.9077 - accuracy: 0.8151 - val_loss: 2.6355 - val_accuracy: 0.8092\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0055 - accuracy: 0.8493WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 1.0055 - accuracy: 0.8493 - val_loss: 2.5153 - val_accuracy: 0.8035\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8704 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 0.8704 - accuracy: 0.8219 - val_loss: 2.4886 - val_accuracy: 0.8035\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1718 - accuracy: 0.7945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 1.1718 - accuracy: 0.7945 - val_loss: 2.4838 - val_accuracy: 0.7861\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 1.0160 - accuracy: 0.8151 - val_loss: 2.4399 - val_accuracy: 0.7861\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1189 - accuracy: 0.8288WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 1.1189 - accuracy: 0.8288 - val_loss: 2.4208 - val_accuracy: 0.7861\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 1.1712 - accuracy: 0.8014 - val_loss: 2.5250 - val_accuracy: 0.7861\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3368 - accuracy: 0.7808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 1.3368 - accuracy: 0.7808 - val_loss: 2.6499 - val_accuracy: 0.7977\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7520 - accuracy: 0.8493WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.7520 - accuracy: 0.8493 - val_loss: 2.7673 - val_accuracy: 0.7919\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7851 - accuracy: 0.8425WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.7851 - accuracy: 0.8425 - val_loss: 2.8706 - val_accuracy: 0.7977\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8201 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.8201 - accuracy: 0.8082 - val_loss: 2.9321 - val_accuracy: 0.7861\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8692 - accuracy: 0.8425WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.8692 - accuracy: 0.8425 - val_loss: 2.9383 - val_accuracy: 0.7861\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6543 - accuracy: 0.8562WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.6543 - accuracy: 0.8562 - val_loss: 2.9287 - val_accuracy: 0.7861\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9691 - accuracy: 0.8493WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.9691 - accuracy: 0.8493 - val_loss: 2.8874 - val_accuracy: 0.7803\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9744 - accuracy: 0.8014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.9744 - accuracy: 0.8014 - val_loss: 2.9312 - val_accuracy: 0.7630\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7932 - accuracy: 0.8630WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.7932 - accuracy: 0.8630 - val_loss: 3.0175 - val_accuracy: 0.7803\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9159 - accuracy: 0.8562WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.9159 - accuracy: 0.8562 - val_loss: 3.0760 - val_accuracy: 0.7803\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8049 - accuracy: 0.8425WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.8049 - accuracy: 0.8425 - val_loss: 3.0312 - val_accuracy: 0.7746\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8922 - accuracy: 0.8699WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.8922 - accuracy: 0.8699 - val_loss: 2.9504 - val_accuracy: 0.7746\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5808 - accuracy: 0.8699WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.5808 - accuracy: 0.8699 - val_loss: 2.8635 - val_accuracy: 0.7572\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8221 - accuracy: 0.8219WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.8221 - accuracy: 0.8219 - val_loss: 2.8179 - val_accuracy: 0.7630\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8266 - accuracy: 0.8767WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.8266 - accuracy: 0.8767 - val_loss: 2.8110 - val_accuracy: 0.7803\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7176 - accuracy: 0.8904WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.7176 - accuracy: 0.8904 - val_loss: 2.7716 - val_accuracy: 0.8035\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7244 - accuracy: 0.8493WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.7244 - accuracy: 0.8493 - val_loss: 2.7264 - val_accuracy: 0.8035\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.8493WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.7625 - accuracy: 0.8493 - val_loss: 2.5874 - val_accuracy: 0.8035\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.8562WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.6931 - accuracy: 0.8562 - val_loss: 2.4429 - val_accuracy: 0.7977\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9583 - accuracy: 0.8082WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.9583 - accuracy: 0.8082 - val_loss: 2.4455 - val_accuracy: 0.7977\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6855 - accuracy: 0.8904WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.6855 - accuracy: 0.8904 - val_loss: 2.5639 - val_accuracy: 0.7977\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8642 - accuracy: 0.8562WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.8642 - accuracy: 0.8562 - val_loss: 2.7960 - val_accuracy: 0.7919\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8829 - accuracy: 0.8767WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.8829 - accuracy: 0.8767 - val_loss: 3.0584 - val_accuracy: 0.7977\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7394 - accuracy: 0.8767WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.7394 - accuracy: 0.8767 - val_loss: 3.1224 - val_accuracy: 0.7977\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1808 - accuracy: 0.8151WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 1.1808 - accuracy: 0.8151 - val_loss: 3.0298 - val_accuracy: 0.7746\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2759 - accuracy: 0.8425WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 1.2759 - accuracy: 0.8425 - val_loss: 2.9268 - val_accuracy: 0.7630\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "bridge_df = pd.DataFrame(labels, columns=['Class'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "bridge_df['Class_cat'] = labelencoder.fit_transform(bridge_df['Class'])\n",
        "\n",
        "y = bridge_df[['Class_cat']].to_numpy()\n",
        "y_pred, y_test, DNN_model = trainModel(np.array(sounds).reshape(len(sounds),40,1), np.array(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNReI30_57kG",
        "outputId": "7d8c61df-3679-443f-8ff8-bbe8be614b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.1125043e-16 1.0728270e-15 1.0000000e+00 5.4740378e-14 6.1422532e-18\n",
            "  4.0402298e-22]\n",
            " [4.2972743e-04 4.3157146e-05 9.7648990e-01 2.3020977e-02 1.6224541e-05\n",
            "  1.6321364e-07]\n",
            " [1.5469562e-18 1.7283180e-17 1.0000000e+00 5.2903550e-16 3.0832994e-21\n",
            "  1.1101750e-25]\n",
            " ...\n",
            " [2.3248536e-03 1.0226683e-02 8.5135043e-01 3.8598277e-02 9.6671060e-02\n",
            "  8.2862645e-04]\n",
            " [1.4188667e-03 5.4730936e-03 9.3846369e-01 3.4702558e-02 1.9782707e-02\n",
            "  1.5909955e-04]\n",
            " [2.1369283e-14 1.0005576e-14 1.0000000e+00 4.5619444e-13 2.4366973e-16\n",
            "  1.2082587e-19]]\n",
            "<keras.engine.functional.Functional object at 0x7f30dc141650>\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "print(y_pred)\n",
        "print(DNN_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMaiGRxMvuZF",
        "outputId": "821aedf2-14ba-4cdf-a077-d3ba3781ac62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(173, 1) (173, 1)\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "yt_pred = np.argmax(y_pred, axis=1)\n",
        "yt_pred = yt_pred.reshape(len(yt_pred),1)\n",
        "print(yt_pred.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeIeWS6Ewr4-",
        "outputId": "07fbf2a7-1e08-42e2-fb4b-7191716c0997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.763006\n",
            "Precision: 0.665920\n",
            "Recall: 0.763006\n",
            "F1 score: 0.705586\n",
            "Cohens kappa: 0.029685\n",
            "Matthews correlation coefficient: 0.036758\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.80      0.94      0.86       138\n",
            "           3       0.50      0.17      0.25         6\n",
            "           4       0.14      0.07      0.09        15\n",
            "           5       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.76       173\n",
            "   macro avg       0.24      0.20      0.20       173\n",
            "weighted avg       0.67      0.76      0.71       173\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.7630057803468208,\n",
              " 'Cohens kappa': 0.029685362517099967,\n",
              " 'F1 score': 0.7055855154389903,\n",
              " 'Matthews correlation coefficient': 0.036757570874220616,\n",
              " 'Precision': 0.6659202707289519,\n",
              " 'Recall': 0.7630057803468208}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#take\n",
        "evalModel(y_test, yt_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifu1hoWh803r",
        "outputId": "399581d2-2d4d-43a5-af75-11e6d1d5edc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6480, 6)\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.6623 - accuracy: 0.1707WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 41s 41s/step - loss: 2.6623 - accuracy: 0.1707 - val_loss: 1.9079 - val_accuracy: 0.2310\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.1386 - accuracy: 0.1911WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 2.1386 - accuracy: 0.1911 - val_loss: 1.9555 - val_accuracy: 0.2076\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0415 - accuracy: 0.1904WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 19s 19s/step - loss: 2.0415 - accuracy: 0.1904 - val_loss: 1.9771 - val_accuracy: 0.1907\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9383 - accuracy: 0.2136WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.9383 - accuracy: 0.2136 - val_loss: 1.9796 - val_accuracy: 0.2059\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9256 - accuracy: 0.2183WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.9256 - accuracy: 0.2183 - val_loss: 1.9746 - val_accuracy: 0.2427\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9553 - accuracy: 0.2288WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.9553 - accuracy: 0.2288 - val_loss: 1.9529 - val_accuracy: 0.3066\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9070 - accuracy: 0.2404WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.9070 - accuracy: 0.2404 - val_loss: 1.9424 - val_accuracy: 0.3534\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9109 - accuracy: 0.2495WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.9109 - accuracy: 0.2495 - val_loss: 1.9237 - val_accuracy: 0.3534\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9075 - accuracy: 0.2518WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.9075 - accuracy: 0.2518 - val_loss: 1.8968 - val_accuracy: 0.3534\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8316 - accuracy: 0.2578WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.8316 - accuracy: 0.2578 - val_loss: 1.8729 - val_accuracy: 0.3523\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8504 - accuracy: 0.2795WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.8504 - accuracy: 0.2795 - val_loss: 1.8452 - val_accuracy: 0.3523\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8266 - accuracy: 0.2851WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.8266 - accuracy: 0.2851 - val_loss: 1.8190 - val_accuracy: 0.3523\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8090 - accuracy: 0.2942WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.8090 - accuracy: 0.2942 - val_loss: 1.7881 - val_accuracy: 0.3523\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8056 - accuracy: 0.3005WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.8056 - accuracy: 0.3005 - val_loss: 1.7671 - val_accuracy: 0.4046\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.8364 - accuracy: 0.3072WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.8364 - accuracy: 0.3072 - val_loss: 1.7573 - val_accuracy: 0.4238\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7722 - accuracy: 0.3091WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 19s 19s/step - loss: 1.7722 - accuracy: 0.3091 - val_loss: 1.7453 - val_accuracy: 0.4302\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7758 - accuracy: 0.3230WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.7758 - accuracy: 0.3230 - val_loss: 1.7405 - val_accuracy: 0.4725\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7741 - accuracy: 0.3326WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.7741 - accuracy: 0.3326 - val_loss: 1.7403 - val_accuracy: 0.4503\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7733 - accuracy: 0.3371WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.7733 - accuracy: 0.3371 - val_loss: 1.7297 - val_accuracy: 0.4707\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7171 - accuracy: 0.3409WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.7171 - accuracy: 0.3409 - val_loss: 1.7130 - val_accuracy: 0.4404\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7325 - accuracy: 0.3397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 23s 23s/step - loss: 1.7325 - accuracy: 0.3397 - val_loss: 1.6958 - val_accuracy: 0.4781\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7224 - accuracy: 0.3437WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.7224 - accuracy: 0.3437 - val_loss: 1.6834 - val_accuracy: 0.5184\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7057 - accuracy: 0.3529WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.7057 - accuracy: 0.3529 - val_loss: 1.6695 - val_accuracy: 0.4767\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6733 - accuracy: 0.3527WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 19s 19s/step - loss: 1.6733 - accuracy: 0.3527 - val_loss: 1.6542 - val_accuracy: 0.4767\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6751 - accuracy: 0.3476WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 19s 19s/step - loss: 1.6751 - accuracy: 0.3476 - val_loss: 1.6419 - val_accuracy: 0.4702\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6564 - accuracy: 0.3594WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 19s 19s/step - loss: 1.6564 - accuracy: 0.3594 - val_loss: 1.6288 - val_accuracy: 0.4702\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6187 - accuracy: 0.3585WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 19s 19s/step - loss: 1.6187 - accuracy: 0.3585 - val_loss: 1.6177 - val_accuracy: 0.4770\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6383 - accuracy: 0.3659WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.6383 - accuracy: 0.3659 - val_loss: 1.5971 - val_accuracy: 0.4769\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6199 - accuracy: 0.3683WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.6199 - accuracy: 0.3683 - val_loss: 1.5821 - val_accuracy: 0.4900\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6200 - accuracy: 0.3658WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 19s 19s/step - loss: 1.6200 - accuracy: 0.3658 - val_loss: 1.5631 - val_accuracy: 0.4468\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5838 - accuracy: 0.3639WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 24s 24s/step - loss: 1.5838 - accuracy: 0.3639 - val_loss: 1.5493 - val_accuracy: 0.4248\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5845 - accuracy: 0.3645WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 21s 21s/step - loss: 1.5845 - accuracy: 0.3645 - val_loss: 1.5415 - val_accuracy: 0.4248\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5732 - accuracy: 0.3685WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.5732 - accuracy: 0.3685 - val_loss: 1.5331 - val_accuracy: 0.4248\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5703 - accuracy: 0.3708WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.5703 - accuracy: 0.3708 - val_loss: 1.5231 - val_accuracy: 0.4248\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5434 - accuracy: 0.3783WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.5434 - accuracy: 0.3783 - val_loss: 1.5100 - val_accuracy: 0.4248\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5351 - accuracy: 0.3864WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.5351 - accuracy: 0.3864 - val_loss: 1.4957 - val_accuracy: 0.4248\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5359 - accuracy: 0.3873WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.5359 - accuracy: 0.3873 - val_loss: 1.4828 - val_accuracy: 0.4306\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5280 - accuracy: 0.3909WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.5280 - accuracy: 0.3909 - val_loss: 1.4708 - val_accuracy: 0.4306\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.5182 - accuracy: 0.3812WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.5182 - accuracy: 0.3812 - val_loss: 1.4603 - val_accuracy: 0.4306\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4991 - accuracy: 0.3955WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4991 - accuracy: 0.3955 - val_loss: 1.4513 - val_accuracy: 0.4313\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4804 - accuracy: 0.3958WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4804 - accuracy: 0.3958 - val_loss: 1.4453 - val_accuracy: 0.4315\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4930 - accuracy: 0.3866WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4930 - accuracy: 0.3866 - val_loss: 1.4419 - val_accuracy: 0.4449\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4609 - accuracy: 0.3967WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4609 - accuracy: 0.3967 - val_loss: 1.4403 - val_accuracy: 0.4940\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4829 - accuracy: 0.3976WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4829 - accuracy: 0.3976 - val_loss: 1.4322 - val_accuracy: 0.4969\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4652 - accuracy: 0.4047WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4652 - accuracy: 0.4047 - val_loss: 1.4171 - val_accuracy: 0.4998\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4481 - accuracy: 0.4107WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4481 - accuracy: 0.4107 - val_loss: 1.4020 - val_accuracy: 0.5062\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4506 - accuracy: 0.4226WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4506 - accuracy: 0.4226 - val_loss: 1.3861 - val_accuracy: 0.4670\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4330 - accuracy: 0.4205WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4330 - accuracy: 0.4205 - val_loss: 1.3771 - val_accuracy: 0.4724\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4281 - accuracy: 0.4270WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4281 - accuracy: 0.4270 - val_loss: 1.3738 - val_accuracy: 0.4725\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4478 - accuracy: 0.4199WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4478 - accuracy: 0.4199 - val_loss: 1.3683 - val_accuracy: 0.4769\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4094 - accuracy: 0.4433WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4094 - accuracy: 0.4433 - val_loss: 1.3595 - val_accuracy: 0.4784\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4018 - accuracy: 0.4388WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4018 - accuracy: 0.4388 - val_loss: 1.3503 - val_accuracy: 0.4755\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3944 - accuracy: 0.4322WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3944 - accuracy: 0.4322 - val_loss: 1.3330 - val_accuracy: 0.4722\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4030 - accuracy: 0.4389WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4030 - accuracy: 0.4389 - val_loss: 1.3251 - val_accuracy: 0.4755\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4182 - accuracy: 0.4339WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.4182 - accuracy: 0.4339 - val_loss: 1.3211 - val_accuracy: 0.4861\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3969 - accuracy: 0.4310WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3969 - accuracy: 0.4310 - val_loss: 1.3157 - val_accuracy: 0.5022\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3600 - accuracy: 0.4533WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3600 - accuracy: 0.4533 - val_loss: 1.3121 - val_accuracy: 0.5096\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3918 - accuracy: 0.4538WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3918 - accuracy: 0.4538 - val_loss: 1.3128 - val_accuracy: 0.5551\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3859 - accuracy: 0.4549WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3859 - accuracy: 0.4549 - val_loss: 1.3099 - val_accuracy: 0.5571\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3811 - accuracy: 0.4475WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 19s 19s/step - loss: 1.3811 - accuracy: 0.4475 - val_loss: 1.3021 - val_accuracy: 0.5574\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3533 - accuracy: 0.4560WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3533 - accuracy: 0.4560 - val_loss: 1.2913 - val_accuracy: 0.6147\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3430 - accuracy: 0.4649WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 23s 23s/step - loss: 1.3430 - accuracy: 0.4649 - val_loss: 1.2804 - val_accuracy: 0.6164\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3546 - accuracy: 0.4582WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 21s 21s/step - loss: 1.3546 - accuracy: 0.4582 - val_loss: 1.2698 - val_accuracy: 0.6181\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3574 - accuracy: 0.4621WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3574 - accuracy: 0.4621 - val_loss: 1.2682 - val_accuracy: 0.6219\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3313 - accuracy: 0.4696WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3313 - accuracy: 0.4696 - val_loss: 1.2683 - val_accuracy: 0.6244\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3428 - accuracy: 0.4732WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3428 - accuracy: 0.4732 - val_loss: 1.2612 - val_accuracy: 0.6299\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3239 - accuracy: 0.4799WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3239 - accuracy: 0.4799 - val_loss: 1.2535 - val_accuracy: 0.6298\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3093 - accuracy: 0.4806WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 21s 21s/step - loss: 1.3093 - accuracy: 0.4806 - val_loss: 1.2427 - val_accuracy: 0.6278\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3021 - accuracy: 0.4826WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3021 - accuracy: 0.4826 - val_loss: 1.2343 - val_accuracy: 0.5693\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3145 - accuracy: 0.4799WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3145 - accuracy: 0.4799 - val_loss: 1.2287 - val_accuracy: 0.5704\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3095 - accuracy: 0.4792WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.3095 - accuracy: 0.4792 - val_loss: 1.2209 - val_accuracy: 0.6275\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2818 - accuracy: 0.4924WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.2818 - accuracy: 0.4924 - val_loss: 1.2078 - val_accuracy: 0.5674\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2956 - accuracy: 0.4906WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 22s 22s/step - loss: 1.2956 - accuracy: 0.4906 - val_loss: 1.2057 - val_accuracy: 0.5674\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2689 - accuracy: 0.5053WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.2689 - accuracy: 0.5053 - val_loss: 1.2046 - val_accuracy: 0.5664\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2729 - accuracy: 0.5025WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 28s 28s/step - loss: 1.2729 - accuracy: 0.5025 - val_loss: 1.2059 - val_accuracy: 0.5657\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2598 - accuracy: 0.4917WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 31s 31s/step - loss: 1.2598 - accuracy: 0.4917 - val_loss: 1.2012 - val_accuracy: 0.5670\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2689 - accuracy: 0.5145WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 27s 27s/step - loss: 1.2689 - accuracy: 0.5145 - val_loss: 1.1925 - val_accuracy: 0.5736\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2749 - accuracy: 0.5176WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 31s 31s/step - loss: 1.2749 - accuracy: 0.5176 - val_loss: 1.1797 - val_accuracy: 0.5750\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2664 - accuracy: 0.5172WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 35s 35s/step - loss: 1.2664 - accuracy: 0.5172 - val_loss: 1.1632 - val_accuracy: 0.5752\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2311 - accuracy: 0.5203WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.2311 - accuracy: 0.5203 - val_loss: 1.1516 - val_accuracy: 0.5744\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2222 - accuracy: 0.5272WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.2222 - accuracy: 0.5272 - val_loss: 1.1429 - val_accuracy: 0.5789\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2186 - accuracy: 0.5221WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.2186 - accuracy: 0.5221 - val_loss: 1.1346 - val_accuracy: 0.6387\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2195 - accuracy: 0.5328WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 21s 21s/step - loss: 1.2195 - accuracy: 0.5328 - val_loss: 1.1282 - val_accuracy: 0.6242\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2436 - accuracy: 0.5272WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.2436 - accuracy: 0.5272 - val_loss: 1.1022 - val_accuracy: 0.6228\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2083 - accuracy: 0.5332WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.2083 - accuracy: 0.5332 - val_loss: 1.0920 - val_accuracy: 0.6227\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1777 - accuracy: 0.5386WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.1777 - accuracy: 0.5386 - val_loss: 1.0965 - val_accuracy: 0.6826\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2086 - accuracy: 0.5373WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.2086 - accuracy: 0.5373 - val_loss: 1.0924 - val_accuracy: 0.6823\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1852 - accuracy: 0.5569WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.1852 - accuracy: 0.5569 - val_loss: 1.0778 - val_accuracy: 0.6250\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1835 - accuracy: 0.5560WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 21s 21s/step - loss: 1.1835 - accuracy: 0.5560 - val_loss: 1.0602 - val_accuracy: 0.6264\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1509 - accuracy: 0.5591WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 31s 31s/step - loss: 1.1509 - accuracy: 0.5591 - val_loss: 1.0507 - val_accuracy: 0.6852\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1515 - accuracy: 0.5690WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.1515 - accuracy: 0.5690 - val_loss: 1.0399 - val_accuracy: 0.6866\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1597 - accuracy: 0.5598WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.1597 - accuracy: 0.5598 - val_loss: 1.0281 - val_accuracy: 0.6287\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1347 - accuracy: 0.5732WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 21s 21s/step - loss: 1.1347 - accuracy: 0.5732 - val_loss: 1.0171 - val_accuracy: 0.6304\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1329 - accuracy: 0.5743WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.1329 - accuracy: 0.5743 - val_loss: 1.0117 - val_accuracy: 0.6897\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1285 - accuracy: 0.5620WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.1285 - accuracy: 0.5620 - val_loss: 1.0026 - val_accuracy: 0.7437\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1159 - accuracy: 0.5748WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.1159 - accuracy: 0.5748 - val_loss: 0.9866 - val_accuracy: 0.6872\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1027 - accuracy: 0.5795WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.1027 - accuracy: 0.5795 - val_loss: 0.9767 - val_accuracy: 0.6877\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0899 - accuracy: 0.5870WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0899 - accuracy: 0.5870 - val_loss: 0.9697 - val_accuracy: 0.7983\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0785 - accuracy: 0.5877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0785 - accuracy: 0.5877 - val_loss: 0.9699 - val_accuracy: 0.7995\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0699 - accuracy: 0.5993WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0699 - accuracy: 0.5993 - val_loss: 0.9633 - val_accuracy: 0.7992\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0476 - accuracy: 0.6096WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0476 - accuracy: 0.6096 - val_loss: 0.9504 - val_accuracy: 0.7995\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0729 - accuracy: 0.5920WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0729 - accuracy: 0.5920 - val_loss: 0.9405 - val_accuracy: 0.8008\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0387 - accuracy: 0.6136WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0387 - accuracy: 0.6136 - val_loss: 0.9379 - val_accuracy: 0.7619\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0452 - accuracy: 0.6071WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0452 - accuracy: 0.6071 - val_loss: 0.9188 - val_accuracy: 0.7614\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0349 - accuracy: 0.6183WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0349 - accuracy: 0.6183 - val_loss: 0.8911 - val_accuracy: 0.7704\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0202 - accuracy: 0.6139WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0202 - accuracy: 0.6139 - val_loss: 0.8719 - val_accuracy: 0.7704\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0226 - accuracy: 0.6167WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 1.0226 - accuracy: 0.6167 - val_loss: 0.8680 - val_accuracy: 0.7747\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9855 - accuracy: 0.6290WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.9855 - accuracy: 0.6290 - val_loss: 0.8637 - val_accuracy: 0.7764\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9771 - accuracy: 0.6384WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.9771 - accuracy: 0.6384 - val_loss: 0.8551 - val_accuracy: 0.7752\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9777 - accuracy: 0.6391WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.9777 - accuracy: 0.6391 - val_loss: 0.8440 - val_accuracy: 0.7373\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9592 - accuracy: 0.6415WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.9592 - accuracy: 0.6415 - val_loss: 0.8320 - val_accuracy: 0.7390\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.6462WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.9524 - accuracy: 0.6462 - val_loss: 0.8133 - val_accuracy: 0.7383\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9503 - accuracy: 0.6505WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.9503 - accuracy: 0.6505 - val_loss: 0.7965 - val_accuracy: 0.7784\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9244 - accuracy: 0.6433WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.9244 - accuracy: 0.6433 - val_loss: 0.7835 - val_accuracy: 0.7387\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9090 - accuracy: 0.6583WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.9090 - accuracy: 0.6583 - val_loss: 0.7671 - val_accuracy: 0.7409\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9022 - accuracy: 0.6699WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.9022 - accuracy: 0.6699 - val_loss: 0.7458 - val_accuracy: 0.8248\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8858 - accuracy: 0.6665WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.8858 - accuracy: 0.6665 - val_loss: 0.7338 - val_accuracy: 0.8250\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8669 - accuracy: 0.6685WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.8669 - accuracy: 0.6685 - val_loss: 0.7239 - val_accuracy: 0.8284\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8551 - accuracy: 0.6752WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.8551 - accuracy: 0.6752 - val_loss: 0.7120 - val_accuracy: 0.8406\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8396 - accuracy: 0.6763WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 24s 24s/step - loss: 0.8396 - accuracy: 0.6763 - val_loss: 0.7023 - val_accuracy: 0.8415\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8422 - accuracy: 0.6750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.8422 - accuracy: 0.6750 - val_loss: 0.6962 - val_accuracy: 0.7563\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8149 - accuracy: 0.6846WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.8149 - accuracy: 0.6846 - val_loss: 0.6808 - val_accuracy: 0.8438\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8230 - accuracy: 0.6886WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.8230 - accuracy: 0.6886 - val_loss: 0.6677 - val_accuracy: 0.7559\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7892 - accuracy: 0.6884WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.7892 - accuracy: 0.6884 - val_loss: 0.6645 - val_accuracy: 0.7565\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7957 - accuracy: 0.6884WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.7957 - accuracy: 0.6884 - val_loss: 0.6388 - val_accuracy: 0.8437\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7501 - accuracy: 0.7078WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.7501 - accuracy: 0.7078 - val_loss: 0.6165 - val_accuracy: 0.8858\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7462 - accuracy: 0.7007WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.7462 - accuracy: 0.7007 - val_loss: 0.6055 - val_accuracy: 0.7644\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7441 - accuracy: 0.7183WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.7441 - accuracy: 0.7183 - val_loss: 0.5926 - val_accuracy: 0.8858\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7366 - accuracy: 0.7143WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.7366 - accuracy: 0.7143 - val_loss: 0.5870 - val_accuracy: 0.8858\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7156 - accuracy: 0.7194WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.7156 - accuracy: 0.7194 - val_loss: 0.5770 - val_accuracy: 0.8995\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7089 - accuracy: 0.7257WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.7089 - accuracy: 0.7257 - val_loss: 0.5635 - val_accuracy: 0.8983\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.7330WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6789 - accuracy: 0.7330 - val_loss: 0.5648 - val_accuracy: 0.8835\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6619 - accuracy: 0.7388WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6619 - accuracy: 0.7388 - val_loss: 0.5700 - val_accuracy: 0.9034\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.7393WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6876 - accuracy: 0.7393 - val_loss: 0.5501 - val_accuracy: 0.8651\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.7371WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6773 - accuracy: 0.7371 - val_loss: 0.5485 - val_accuracy: 0.8875\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.7444WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6401 - accuracy: 0.7444 - val_loss: 0.5391 - val_accuracy: 0.9085\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.7516WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6225 - accuracy: 0.7516 - val_loss: 0.5247 - val_accuracy: 0.9083\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.7571WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6158 - accuracy: 0.7571 - val_loss: 0.5014 - val_accuracy: 0.9060\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7498WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6088 - accuracy: 0.7498 - val_loss: 0.4859 - val_accuracy: 0.9062\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6027 - accuracy: 0.7623WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6027 - accuracy: 0.7623 - val_loss: 0.4789 - val_accuracy: 0.8642\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5920 - accuracy: 0.7636WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.5920 - accuracy: 0.7636 - val_loss: 0.4652 - val_accuracy: 0.8640\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.7699WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.5866 - accuracy: 0.7699 - val_loss: 0.4652 - val_accuracy: 0.8647\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.7784WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.5600 - accuracy: 0.7784 - val_loss: 0.4672 - val_accuracy: 0.8665\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5352 - accuracy: 0.7886WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.5352 - accuracy: 0.7886 - val_loss: 0.4533 - val_accuracy: 0.8662\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5506 - accuracy: 0.7837WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.5506 - accuracy: 0.7837 - val_loss: 0.4438 - val_accuracy: 0.8770\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5360 - accuracy: 0.7866WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.5360 - accuracy: 0.7866 - val_loss: 0.4334 - val_accuracy: 0.8776\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.7908WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.5175 - accuracy: 0.7908 - val_loss: 0.4245 - val_accuracy: 0.8778\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5096 - accuracy: 0.7989WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.5096 - accuracy: 0.7989 - val_loss: 0.4219 - val_accuracy: 0.8778\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.8076WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.5062 - accuracy: 0.8076 - val_loss: 0.4132 - val_accuracy: 0.8784\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.8078WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4984 - accuracy: 0.8078 - val_loss: 0.4088 - val_accuracy: 0.8785\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.8087WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 27s 27s/step - loss: 0.4887 - accuracy: 0.8087 - val_loss: 0.3975 - val_accuracy: 0.8787\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.8111WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4688 - accuracy: 0.8111 - val_loss: 0.3881 - val_accuracy: 0.9265\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.8076WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4792 - accuracy: 0.8076 - val_loss: 0.3718 - val_accuracy: 0.9199\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4590 - accuracy: 0.8159WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4590 - accuracy: 0.8159 - val_loss: 0.3649 - val_accuracy: 0.9253\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.8234WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4500 - accuracy: 0.8234 - val_loss: 0.3573 - val_accuracy: 0.9259\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4486 - accuracy: 0.8275WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4486 - accuracy: 0.8275 - val_loss: 0.3563 - val_accuracy: 0.9196\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.8317WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4364 - accuracy: 0.8317 - val_loss: 0.3636 - val_accuracy: 0.9258\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4199 - accuracy: 0.8308WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4199 - accuracy: 0.8308 - val_loss: 0.3670 - val_accuracy: 0.9201\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.8341WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4230 - accuracy: 0.8341 - val_loss: 0.3614 - val_accuracy: 0.9253\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.8337WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4164 - accuracy: 0.8337 - val_loss: 0.3378 - val_accuracy: 0.9191\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.8332WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4170 - accuracy: 0.8332 - val_loss: 0.3273 - val_accuracy: 0.9250\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4026 - accuracy: 0.8353WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.4026 - accuracy: 0.8353 - val_loss: 0.3175 - val_accuracy: 0.9187\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3733 - accuracy: 0.8440WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3733 - accuracy: 0.8440 - val_loss: 0.3186 - val_accuracy: 0.9252\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.8487WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3924 - accuracy: 0.8487 - val_loss: 0.3167 - val_accuracy: 0.9256\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.8449WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3763 - accuracy: 0.8449 - val_loss: 0.3203 - val_accuracy: 0.9177\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3802 - accuracy: 0.8449WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3802 - accuracy: 0.8449 - val_loss: 0.3242 - val_accuracy: 0.9242\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.8533WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3642 - accuracy: 0.8533 - val_loss: 0.3229 - val_accuracy: 0.9250\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.8643WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3470 - accuracy: 0.8643 - val_loss: 0.3234 - val_accuracy: 0.9253\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.8527WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3557 - accuracy: 0.8527 - val_loss: 0.3221 - val_accuracy: 0.9394\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8621WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3464 - accuracy: 0.8621 - val_loss: 0.3319 - val_accuracy: 0.9392\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.8701WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3277 - accuracy: 0.8701 - val_loss: 0.3406 - val_accuracy: 0.9256\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.8667WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3469 - accuracy: 0.8667 - val_loss: 0.3343 - val_accuracy: 0.9801\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.8746WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3219 - accuracy: 0.8746 - val_loss: 0.3021 - val_accuracy: 0.9802\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.8685WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3263 - accuracy: 0.8685 - val_loss: 0.2929 - val_accuracy: 0.9253\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.8736WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3207 - accuracy: 0.8736 - val_loss: 0.2882 - val_accuracy: 0.9818\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3085 - accuracy: 0.8755WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3085 - accuracy: 0.8755 - val_loss: 0.3099 - val_accuracy: 0.9821\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3236 - accuracy: 0.8750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3236 - accuracy: 0.8750 - val_loss: 0.3085 - val_accuracy: 0.9267\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.8696WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3507 - accuracy: 0.8696 - val_loss: 0.2737 - val_accuracy: 0.9812\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3104 - accuracy: 0.8812WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.3104 - accuracy: 0.8812 - val_loss: 0.2639 - val_accuracy: 0.9807\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2897 - accuracy: 0.8824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2897 - accuracy: 0.8824 - val_loss: 0.2703 - val_accuracy: 0.9384\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.8795WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 24s 24s/step - loss: 0.2954 - accuracy: 0.8795 - val_loss: 0.2660 - val_accuracy: 0.9804\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.8830WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.2864 - accuracy: 0.8830 - val_loss: 0.2615 - val_accuracy: 0.9793\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2896 - accuracy: 0.8832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2896 - accuracy: 0.8832 - val_loss: 0.2798 - val_accuracy: 0.9375\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.8850WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2904 - accuracy: 0.8850 - val_loss: 0.2738 - val_accuracy: 0.9795\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.8861WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2835 - accuracy: 0.8861 - val_loss: 0.2707 - val_accuracy: 0.9806\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.8962WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2700 - accuracy: 0.8962 - val_loss: 0.2814 - val_accuracy: 0.9813\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.8940WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2748 - accuracy: 0.8940 - val_loss: 0.2701 - val_accuracy: 0.9810\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 0.8969WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2630 - accuracy: 0.8969 - val_loss: 0.2645 - val_accuracy: 0.9804\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.9069WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 24s 24s/step - loss: 0.2533 - accuracy: 0.9069 - val_loss: 0.2678 - val_accuracy: 0.9796\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.8947WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2689 - accuracy: 0.8947 - val_loss: 0.2546 - val_accuracy: 0.9799\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.8960WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 24s 24s/step - loss: 0.2532 - accuracy: 0.8960 - val_loss: 0.2567 - val_accuracy: 0.9809\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9109WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2461 - accuracy: 0.9109 - val_loss: 0.2688 - val_accuracy: 0.9818\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.9033WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2518 - accuracy: 0.9033 - val_loss: 0.2642 - val_accuracy: 0.9819\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9062WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2364 - accuracy: 0.9062 - val_loss: 0.2678 - val_accuracy: 0.9818\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2466 - accuracy: 0.9002WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2466 - accuracy: 0.9002 - val_loss: 0.2767 - val_accuracy: 0.9816\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.9092WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2410 - accuracy: 0.9092 - val_loss: 0.2650 - val_accuracy: 0.9812\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9062WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2295 - accuracy: 0.9062 - val_loss: 0.2691 - val_accuracy: 0.9813\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9091WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2362 - accuracy: 0.9091 - val_loss: 0.2649 - val_accuracy: 0.9816\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9092WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2302 - accuracy: 0.9092 - val_loss: 0.2431 - val_accuracy: 0.9824\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9158WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.2179 - accuracy: 0.9158 - val_loss: 0.2397 - val_accuracy: 0.9826\n",
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "bridge_df = pd.DataFrame(new_y, columns=['Class'])\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "# Assigning numerical values and storing in another column\n",
        "bridge_df['Class_cat'] = labelencoder.fit_transform(bridge_df['Class'])\n",
        "\n",
        "y_new = bridge_df[['Class_cat']].to_numpy()\n",
        "y_pred_new, y_test_new, GAN_DNN_model = trainModel(np.array(new_x).reshape(len(new_x),40,1), np.array(y_new))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z8hofVTCPjW",
        "outputId": "ee3f454a-b2b5-4084-a377-dcf99fa68507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6480, 1) (6480, 1)\n"
          ]
        }
      ],
      "source": [
        "#take\n",
        "yt_pred_new = np.argmax(y_pred_new, axis=1)\n",
        "yt_pred_new = yt_pred_new.reshape(len(yt_pred_new),1)\n",
        "print(yt_pred_new.shape, y_test_new.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_xzmDA9EoOl",
        "outputId": "e4ccecd8-1f11-47bc-f581-48b3dd460e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.982562\n",
            "Precision: 0.983005\n",
            "Recall: 0.982562\n",
            "F1 score: 0.982538\n",
            "Cohens kappa: 0.979071\n",
            "Matthews correlation coefficient: 0.979174\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1107\n",
            "           1       1.00      1.00      1.00      1067\n",
            "           2       0.97      0.92      0.95      1085\n",
            "           3       1.00      0.99      0.99      1062\n",
            "           4       0.93      0.99      0.96      1112\n",
            "           5       1.00      1.00      1.00      1047\n",
            "\n",
            "    accuracy                           0.98      6480\n",
            "   macro avg       0.98      0.98      0.98      6480\n",
            "weighted avg       0.98      0.98      0.98      6480\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.9825617283950617,\n",
              " 'Cohens kappa': 0.9790709268180418,\n",
              " 'F1 score': 0.9825379379259611,\n",
              " 'Matthews correlation coefficient': 0.9791744073571553,\n",
              " 'Precision': 0.9830051805830259,\n",
              " 'Recall': 0.9825617283950617}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "#take\n",
        "evalModel(y_test_new, yt_pred_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing using all possible Input Cases"
      ],
      "metadata": {
        "id": "NTyJTjb6m6R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bridge_df = pd.DataFrame(TEST_LABELS, columns=['Class'])\n",
        "bridge_df['Class_cat'] = labelencoder.fit_transform(bridge_df['Class'])\n",
        "Y_TEST = bridge_df[['Class_cat']].to_numpy()\n",
        "print(Y_TEST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eg7uGHTlp9f",
        "outputId": "bff6e7e8-99ab-4648-eea2-6d6c7d2cf0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5]\n",
            " [3]\n",
            " [5]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [0]\n",
            " [2]\n",
            " [5]\n",
            " [3]\n",
            " [5]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [0]\n",
            " [2]\n",
            " [0]\n",
            " [2]\n",
            " [5]\n",
            " [3]\n",
            " [4]\n",
            " [3]\n",
            " [5]\n",
            " [5]\n",
            " [4]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_PREDICTED  = GAN_DNN_model.predict(np.array(TEST_DATA).reshape(len(TEST_DATA),40))\n",
        "TEST_PREDICTED = np.argmax(TEST_PREDICTED, axis=1)\n",
        "TEST_PREDICTED = TEST_PREDICTED.reshape(len(TEST_PREDICTED),1)\n",
        "print(TEST_PREDICTED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-7j8ovGP3jd",
        "outputId": "9056c6de-af0e-47a7-f65f-be525d3a7044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5]\n",
            " [3]\n",
            " [5]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [5]\n",
            " [3]\n",
            " [5]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [0]\n",
            " [2]\n",
            " [5]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [5]\n",
            " [4]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics for this test set"
      ],
      "metadata": {
        "id": "KvslBV6vm_Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix\n",
        "print(\"Accuracy score : \" , accuracy_score(Y_TEST,TEST_PREDICTED))\n",
        "print(\"Precision : \", precision_score(Y_TEST,TEST_PREDICTED,average=\"weighted\"))\n",
        "print(\"Confusion Matrix : \\n\", confusion_matrix(Y_TEST, TEST_PREDICTED))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAvAUgYfm-tM",
        "outputId": "5a3f561f-e5ea-4263-af62-82068dd179c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score :  0.7692307692307693\n",
            "Precision :  0.8615384615384615\n",
            "Confusion Matrix : \n",
            " [[1 0 2 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 9 0 0 0]\n",
            " [0 0 2 2 0 0]\n",
            " [0 0 1 0 1 0]\n",
            " [0 0 1 0 0 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labelencoder.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujnHLUR8eW6O",
        "outputId": "897d8151-86d6-4de4-92aa-23de5ffa2c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia',\n",
              "       'URTI'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_NAMES=[\n",
        "            \"105_1b1_Tc_sc_Meditron.wav\",\n",
        "            \"102_1b1_Ar_sc_Meditron.wav\",\n",
        "            \"101_1b1_Pr_sc_Meditron.wav\",\n",
        "            \"104_1b1_Ar_sc_Litt3200.wav\",\n",
        "            \"107_2b4_Pl_mc_AKGC417L.wav\",\n",
        "            \"106_2b1_Pr_mc_LittC2SE.wav\",\n",
        "             \"169_1b1_Lr_sc_Meditron.wav\",\n",
        "             \"118_1b1_Lr_sc_Litt3200.wav\",\n",
        "            \"119_1b1_Ar_sc_Meditron.wav\",\n",
        "            \"194_1b1_Lr_sc_Meditron.wav\",\n",
        "            \"165_1b1_Pl_sc_Meditron.wav\",\n",
        "            \"117_1b2_Tc_mc_LittC2SE.wav\",\n",
        "            \"113_1b1_Al_sc_Litt3200.wav\",\n",
        "            \"112_1p1_Ll_sc_Litt3200.wav\",\n",
        "            \"196_1b1_Pr_sc_Meditron.wav\",\n",
        "            \"201_1b3_Ar_sc_Meditron.wav\",\n",
        "            \"110_1p1_Lr_sc_Meditron.wav\",\n",
        "            \"116_1b2_Pl_sc_Meditron.wav\",\n",
        "             \"131_1b1_Al_sc_Meditron.wav\",\n",
        "            \"183_1b1_Pl_sc_Meditron.wav\",\n",
        "            \"191_2b1_Pr_mc_LittC2SE.wav\",\n",
        "            \"159_1b1_Pr_sc_Meditron.wav\",\n",
        "            \"137_1b1_Ll_sc_Meditron.wav\",\n",
        "            \"219_2b2_Ar_mc_LittC2SE.wav\",\n",
        "            \"167_1b1_Pr_sc_Meditron.wav\",\n",
        "            \"122_2b3_Tc_mc_LittC2SE.wav\", \n",
        "            \"226_1b1_Al_sc_Meditron.wav\",\n",
        "            \"191_2b1_Pl_mc_LittC2SE.wav\",\n",
        "            \"206_1b1_Ar_sc_Meditron.wav\",\n",
        "             \"111_1b3_Tc_sc_Meditron.wav\",\n",
        "            \"121_1p1_Tc_sc_Meditron.wav\",\n",
        "            \"123_1b1_Al_sc_Meditron.wav\",\n",
        "            \"168_1b1_Al_sc_Meditron.wav\",\n",
        "             \"169_1b2_Ll_sc_Meditron.wav\",\n",
        "            \"140_2b3_Ll_mc_LittC2SE.wav\",\n",
        "            \"161_1b1_Pl_sc_Meditron.wav\",\n",
        "            \"173_1b1_Al_sc_Meditron.wav\",\n",
        "            \"149_1b1_Lr_sc_Meditron.wav\",\n",
        "            \"187_1b1_Ll_sc_Meditron.wav\"            \n",
        "            ]\n"
      ],
      "metadata": {
        "id": "EmFQ9A70ZyLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "table = PrettyTable([\"Audio\",\"Actual label\",\"Predicted label\"])\n",
        "for i in range(len(TEST_PREDICTED)):\n",
        "  row = []\n",
        "  row.append(TEST_NAMES[i])\n",
        "  row.append(labelencoder.inverse_transform(np.array(Y_TEST[i]).reshape(1)))\n",
        "  row.append(labelencoder.inverse_transform(np.array(TEST_PREDICTED[i]).reshape(1)))\n",
        "  row = np.array(row).reshape(3)\n",
        "  table.add_row(row)\n",
        "print(table)"
      ],
      "metadata": {
        "id": "LSn89HYpK43a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7a54fb-e675-425b-9eb2-6b7e382be635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+--------------------+--------------------+\n",
            "|           Audio            |    Actual label    |  Predicted label   |\n",
            "+----------------------------+--------------------+--------------------+\n",
            "| 105_1b1_Tc_sc_Meditron.wav |      ['URTI']      |      ['URTI']      |\n",
            "| 102_1b1_Ar_sc_Meditron.wav |    ['Healthy']     |    ['Healthy']     |\n",
            "| 101_1b1_Pr_sc_Meditron.wav |      ['URTI']      |      ['URTI']      |\n",
            "| 104_1b1_Ar_sc_Litt3200.wav |      ['COPD']      |      ['COPD']      |\n",
            "| 107_2b4_Pl_mc_AKGC417L.wav |      ['COPD']      |      ['COPD']      |\n",
            "| 106_2b1_Pr_mc_LittC2SE.wav |      ['COPD']      |      ['COPD']      |\n",
            "| 169_1b1_Lr_sc_Meditron.wav | ['Bronchiectasis'] |      ['COPD']      |\n",
            "| 118_1b1_Lr_sc_Litt3200.wav |      ['COPD']      |      ['COPD']      |\n",
            "| 119_1b1_Ar_sc_Meditron.wav |      ['URTI']      |      ['URTI']      |\n",
            "| 194_1b1_Lr_sc_Meditron.wav |    ['Healthy']     |    ['Healthy']     |\n",
            "| 165_1b1_Pl_sc_Meditron.wav |      ['URTI']      |      ['URTI']      |\n",
            "| 117_1b2_Tc_mc_LittC2SE.wav |      ['COPD']      |      ['COPD']      |\n",
            "| 113_1b1_Al_sc_Litt3200.wav |      ['COPD']      |      ['COPD']      |\n",
            "| 112_1p1_Ll_sc_Litt3200.wav |      ['COPD']      |      ['COPD']      |\n",
            "| 196_1b1_Pr_sc_Meditron.wav | ['Bronchiectasis'] |      ['COPD']      |\n",
            "| 201_1b3_Ar_sc_Meditron.wav |      ['COPD']      |      ['COPD']      |\n",
            "| 110_1p1_Lr_sc_Meditron.wav | ['Bronchiectasis'] | ['Bronchiectasis'] |\n",
            "| 116_1b2_Pl_sc_Meditron.wav |      ['COPD']      |      ['COPD']      |\n",
            "| 131_1b1_Al_sc_Meditron.wav |      ['URTI']      |      ['URTI']      |\n",
            "| 183_1b1_Pl_sc_Meditron.wav |    ['Healthy']     |      ['COPD']      |\n",
            "| 191_2b1_Pr_mc_LittC2SE.wav |   ['Pneumonia']    |      ['COPD']      |\n",
            "| 159_1b1_Pr_sc_Meditron.wav |    ['Healthy']     |      ['COPD']      |\n",
            "| 137_1b1_Ll_sc_Meditron.wav |      ['URTI']      |      ['COPD']      |\n",
            "| 219_2b2_Ar_mc_LittC2SE.wav |      ['URTI']      |      ['URTI']      |\n",
            "| 167_1b1_Pr_sc_Meditron.wav |   ['Pneumonia']    |   ['Pneumonia']    |\n",
            "| 122_2b3_Tc_mc_LittC2SE.wav | ['Bronchiolitis']  | ['Bronchiolitis']  |\n",
            "+----------------------------+--------------------+--------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}